@techreport{Cochrane2005,
abstract = {Figure out the one central and novel contribution of your paper. Write this down in one paragraph. As with all your writing, this must be concrete. Don't write "I analyzed data on executive compensation and found many interesting results." Explain what the central results are. For example, Fama and French 1992 start their abstract with: "Two easily measured variables, size and book-to-market equity, combine to capture the cross-sectional variation in average stock returns associated with market , size, leverage, book-to-market equity, and earnings-price ratios." Distilling your one central contribution will take some thought. It will cause some pain, because you will start to realize how much you're going to have to throw out. Once you do it, though, you're in a much better position to focus the paper on that one contribution, and help readers to get it quickly. Your readers are busy and impatient. No reader will ever read the whole thing from start to nish. Readers skim. You have to make it easy for them to skim. Most readers want to know your basic result. Only a few care how it is digerent from others. Only a few care if it holds up with digerent variable denitions, digerent instrument sets, etc. Organize the paper in "triangular" or "newspaper" style, not in "joke" or "novel" style. Notice how newspapers start with the most important part, then ll in background later for the readers who kept going and want more details. A good joke or a mystery novel has a long windup to the nal punchline. Don't write papers like that-put the punchline right up front and then slowly explain the joke. Readers don't stick around to nd the punchline in Table 12. The vast majority of Ph.D. student papers and workshop presentations (not all by students !) get this exactly wrong, and we never really nd out what the contribution of the paper is until the last page, the last table, and the last 5 minutes of the seminar. A good paper is not a travelogue of your search process. We don't care how you came to gure out the right answer. We don't care about the hundreds of things you tried that did not work. Save it for your memoirs. Abstract Most journals allow 100-150 words. Obey this limit now. The main function of the abstract is to communicate the one central and novel contribution, which you just gured out. You should not mention other literature in the abstract. Like everything else, the abstract must be concrete. Say what you nd, not what you look for. Here too, don't write "data are analyzed, theorems are proved, discussion is made.."},
author = {Cochrane, John H},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cochrane - 2005 - Writing Tips for Ph. D. Students.pdf:pdf},
title = {{Writing Tips for Ph. D. Students}},
url = {http://gsbwww.uchicago.edu/fac/john.cochrane/research/Papers/},
year = {2005}
}
@article{Muller2021,
abstract = {Background: The increased availability and usage of modern medical imaging induced a strong need for automatic medical image segmentation. Still, current image segmentation platforms do not provide the required functionalities for plain setup of medical image segmentation pipelines. Already implemented pipelines are commonly standalone software, optimized on a specific public data set. Therefore, this paper introduces the open-source Python library MIScnn. Implementation: The aim of MIScnn is to provide an intuitive API allowing fast building of medical image segmentation pipelines including data I/O, preprocessing, data augmentation, patch-wise analysis, metrics, a library with state-of-the-art deep learning models and model utilization like training, prediction, as well as fully automatic evaluation (e.g. cross-validation). Similarly, high configurability and multiple open interfaces allow full pipeline customization. Results: Running a cross-validation with MIScnn on the Kidney Tumor Segmentation Challenge 2019 data set (multi-class semantic segmentation with 300 CT scans) resulted into a powerful predictor based on the standard 3D U-Net model. Conclusions: With this experiment, we could show that the MIScnn framework enables researchers to rapidly set up a complete medical image segmentation pipeline by using just a few lines of code. The source code for MIScnn is available in the Git repository: https://github.com/frankkramer-lab/MIScnn.},
archivePrefix = {arXiv},
arxivId = {1910.09308},
author = {M{\"{u}}ller, Dominik and Kramer, Frank},
doi = {10.1186/s12880-020-00543-7},
eprint = {1910.09308},
file = {::},
issn = {14712342},
journal = {BMC Medical Imaging},
keywords = {Biomedical image segmentation,Computer aided diagnosis,Deep learning,Medical image analysis,Open-source framework,U-Net},
month = {dec},
number = {1},
pmid = {33461500},
publisher = {BioMed Central Ltd},
title = {{MIScnn: a framework for medical image segmentation with convolutional neural networks and deep learning}},
volume = {21},
year = {2021}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
eprint = {1512.03385},
file = {::},
month = {dec},
title = {{Deep Residual Learning for Image Recognition}},
url = {http://arxiv.org/abs/1512.03385},
year = {2015}
}
@article{Lu2017,
abstract = {The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-$2$) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-$n$ ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth is more effective than width for the expressiveness of ReLU networks.},
archivePrefix = {arXiv},
arxivId = {1709.02540},
author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
eprint = {1709.02540},
file = {::},
month = {sep},
title = {{The Expressive Power of Neural Networks: A View from the Width}},
url = {http://arxiv.org/abs/1709.02540},
year = {2017}
}
@techreport{Zhang2021,
author = {Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
file = {::},
title = {{Dive into Deep Learning Release 0.16.2}},
year = {2021}
}
@misc{Roy2017,
abstract = {Optical coherence tomography \(OCT\) is used for non-invasive diagnosis of diabetic macular edema assessing the retinal layers. In this paper, we propose a new fully convolutional deep architecture, termed ReLayNet, for end-to-end segmentation of retinal layers and fluid masses in eye OCT scans. ReLayNet uses a contracting path of convolutional blocks \(encoders\) to learn a hierarchy of contextual features, followed by an expansive path of convolutional blocks \(decoders\) for semantic segmentation. ReLayNet is trained to optimize a joint loss function comprising of weighted logistic regression and Dice overlap loss. The framework is validated on a publicly available benchmark dataset with comparisons against five state-of-the-art segmentation methods including two deep learning based approaches to substantiate its effectiveness.},
archivePrefix = {arXiv},
arxivId = {1704.02161},
author = {Roy, Abhijit Guha and Conjeti, Sailesh and Karri, Sri Phani Krishna and Sheet, Debdoot and Katouzian, Amin and Wachinger, Christian and Navab, Nassir},
booktitle = {arXiv},
doi = {10.1364/boe.8.003627},
eprint = {1704.02161},
file = {::},
issn = {23318422},
month = {apr},
pmid = {28856040},
publisher = {arXiv},
title = {{ReLaynet: Retinal layer and fluid segmentation of macular optical coherence tomography using fully convolutional networks}},
year = {2017}
}
@article{Maloca2019,
abstract = {Purpose To benchmark the human and machine performance of spectral-domain (SD) and sweptsource (SS) optical coherence tomography (OCT) image segmentation, i.e., pixel-wise classification, for the compartments vitreous, retina, choroid, sclera. Methods A convolutional neural network (CNN) was trained on OCT B-scan images annotated by a senior ground truth expert retina specialist to segment the posterior eye compartments. Independent benchmark data sets (30 SDOCT and 30 SSOCT) were manually segmented by three classes of graders with varying levels of ophthalmic proficiencies. Nine graders contributed to benchmark an additional 60 images in three consecutive runs. Inter-human and intra-human class agreement was measured and compared to the CNN results. Results The CNN training data consisted of a total of 6210 manually segmented images derived from 2070 B-scans (1046 SDOCT and 1024 SSOCT; 630 C-Scans). The CNN segmentation revealed a high agreement with all grader groups. For all compartments and groups, the mean Intersection over Union (IOU) score of CNN compartmentalization versus group graders' compartmentalization was higher than the mean score for intra-grader group comparison. Conclusion The proposed deep learning segmentation algorithm (CNN) for automated eye compartment segmentation in OCT B-scans (SDOCT and SSOCT) is on par with manual segmentations by human graders.},
author = {Maloca, Peter M. and Lee, Aaron Y. and {De Carvalho}, Emanuel R. and Okada, Mali and Fasler, Katrin and Leung, Irene and H{\"{o}}rmann, Beat and Kaiser, Pascal and Suter, Susanne and Hasler, Pascal W. and Zarranz-Ventura, Javier and Egan, Catherine and Heeren, Tjebo F.C. and Balaskas, Konstantinos and Tufail, Adnan and Scholl, Hendrik P.N.},
doi = {10.1371/journal.pone.0220063},
file = {::},
issn = {19326203},
journal = {PLoS ONE},
month = {aug},
number = {8},
pmid = {31419240},
publisher = {Public Library of Science},
title = {{Validation of automated artificial intelligence segmentation of optical coherence tomography images}},
volume = {14},
year = {2019}
}

@article{Alonso-Caneiro2013,
abstract = {The assessment of choroidal thickness from optical coherence tomography (OCT) images of the human choroid is an important clinical and research task, since it provides valuable information regarding the eye's normal anatomy and physiology, and changes associated with various eye diseases and the development of refractive error. Due to the time consuming and subjective nature of manual image analysis, there is a need for the development of reliable objective automated methods of image segmentation to derive choroidal thickness measures. However, the detection of the two boundaries which delineate the choroid is a complicated and challenging task, in particular the detection of the outer choroidal boundary, due to a number of issues including: (i) the vascular ocular tissue is non-uniform and rich in non-homogeneous features, and (ii) the boundary can have a low contrast. In this paper, an automatic segmentation technique based on graph-search theory is presented to segment the inner choroidal boundary (ICB) and the outer choroidal boundary (OCB) to obtain the choroid thickness profile from OCT images. Before the segmentation, the B-scan is pre-processed to enhance the two boundaries of interest and to minimize the artifacts produced by surrounding features. The algorithm to detect the ICB is based on a simple edge filter and a directional weighted map penalty, while the algorithm to detect the OCB is based on OCT image enhancement and a dual brightness probability gradient. The method was tested on a large data set of images from a pediatric (1083 B-scans) and an adult (90 B-scans) population, which were previously manually segmented by an experienced observer. The results demonstrate the proposed method provides robust detection of the boundaries of interest and is a useful tool to extract clinical data.},
author = {Alonso-Caneiro, David and Read, Scott A. and Collins, Michael J.},
doi = {10.1364/boe.4.002795},
file = {::},
issn = {2156-7085},
journal = {Biomedical Optics Express},
month = {dec},
number = {12},
pages = {2795},
pmid = {24409381},
publisher = {The Optical Society},
title = {{Automatic segmentation of choroidal thickness in optical coherence tomography}},
volume = {4},
year = {2013}
}

@inproceedings{Ronchetti2018,
abstract = {Macular Telangiectasia Type 2 (MacTel2) is a disease of the retina leading to a gradual deterioration of central vision. At the onset of the disease a good visual acuity is present, which declines as the disease progresses to cause reading difficulties. In this paper, we present new insights on the vascular changes in MacTel2. We investigated whether MacTel2 progression correlates to changes in the thickness of the choroid. For this purpose, we apply a recently published registration-based approach to detect deviations in the choroid on a dataset of 45 MacTel2 patients. Between 2012 and 2016 these subjects and a control group were measured twice within variable intervals of time in the Moorfields Eye Hospital in the MacTel Natural History Observation and Registry Study. Our results show that in the MacTel2 group the thickness of the choroid increased while in the control group a decrease was noted. Manual expert segmentation and an automated state-of-the-art method were used to validate the results.},
author = {Ronchetti, Tiziano and Maloca, Peter and de Carvalho, Emanuel Ramos and Heeren, Tjebo F.C. and Balaskas, Konstantinos and Tufail, Adnan and Egan, Catherine and Okada, Mali and Org{\"{u}}l, Selim and Jud, Christoph and Cattin, Philippe C.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-00949-6_36},
file = {::},
isbn = {9783030009489},
issn = {16113349},
keywords = {Choroidal thickness changes,Macular Telangiectasia Type 2,Piecewise rigid registration},
pages = {303--309},
publisher = {Springer Verlag},
title = {{Feasibility Study of Subfoveal Choroidal Thickness Changes in Spectral-Domain Optical Coherence Tomography Measurements of Macular Telangiectasia Type 2}},
volume = {11039 LNCS},
year = {2018}
}

@book{Ronchetti2017,
address = {Cham},
author = {Ronchetti, Tiziano and Maloca, Peter and Jud, Christoph and Meier, Christoph and Et al.},
doi = {10.1007/978-3-319-67561-9},
editor = {Cardoso, M. Jorge and Arbel, Tal and Melbourne, Andrew and Bogunovic, Hrvoje and Moeskops, Pim and Chen, Xinjian and Schwartz, Ernst and Garvin, Mona and Robinson, Emma and Trucco, Emanuele and Ebner, Michael and Xu, Yanwu and Makropoulos, Antonios and Desjardin, Adrien and Vercauteren, Tom},
file = {::},
isbn = {978-3-319-67560-2},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Fetal, Infant and Ophthalmic Medical Image Analysis}},
url = {http://link.springer.com/10.1007/978-3-319-67561-9},
volume = {10554},
year = {2017}
}
@techreport{Fabritius2001,
abstract = {This paper presents optical coherence tomography (OCT) signal intensity variation based segmentation algorithms for retinal layer identification. Its main ambition is to reduce the calculation time required by layer identification algorithms. Two algorithms, one for the identification of the internal limiting membrane (ILM) and the other for retinal pigment epithelium (RPE) identification are implemented to evaluate structural features of the retina. Using a 830 nm spectral domain OCT device, this paper demonstrates a segmentation method for the study of healthy and diseased eyes.},
author = {Fabritius, Tapio and Makita, Shuichi and Miura, Masahiro and Myllyl{\"{a}}, Risto and Yasuno, Yoshiaki and Koozekanani, D and Boyer, K and Roberts, C and Ishikawa, H and Stein, DM and Wollstein, G and Beaton, S and Fujimoto, JG and Schuman, JS and Szkulmowski, M and Wojtkowski, M and Sikorski, B and Bajraszewski, T and Srinivasan, V J and Szkulmowska, A and Kaluzny, J J and Fujimoto, J G and Kowalczyk, A},
booktitle = {Investigative Ophthalmol. Visual Scie},
file = {::},
pages = {2012--2017},
title = {{Image processing; (100.5010) Pattern recognition and feature ex-traction; (170.4470) Ophthalmology; (170.4500) Optical coherence tomography; (170.4580) Optical diagnostics for medicine}},
volume = {20},
year = {2001}
}
@article{Kugelman2019,
abstract = {The analysis of the choroid in the eye is crucial for our understanding of a range of ocular diseases and physiological processes. Optical coherence tomography (OCT) imaging provides the ability to capture highly detailed cross-sectional images of the choroid yet only a very limited number of commercial OCT instruments provide methods for automatic segmentation of choroidal tissue. Manual annotation of the choroidal boundaries is often performed but this is impractical due to the lengthy time taken to analyse large volumes of images. Therefore, there is a pressing need for reliable and accurate methods to automatically segment choroidal tissue boundaries in OCT images. In this work, a variety of patch-based and fully-convolutional deep learning methods are proposed to accurately determine the location of the choroidal boundaries of interest. The effect of network architecture, patch-size and contrast enhancement methods was tested to better understand the optimal architecture and approach to maximize performance. The results are compared with manual boundary segmentation used as a ground-truth, as well as with a standard image analysis technique. Results of total retinal layer segmentation are also presented for comparison purposes. The findings presented here demonstrate the benefit of deep learning methods for segmentation of the chorio-retinal boundary analysis in OCT images.},
author = {Kugelman, Jason and Alonso-Caneiro, David and Read, Scott A. and Hamwood, Jared and Vincent, Stephen J. and Chen, Fred K. and Collins, Michael J.},
doi = {10.1038/s41598-019-49816-4},
file = {::},
issn = {20452322},
journal = {Scientific Reports},
month = {dec},
number = {1},
pmid = {31527630},
publisher = {Nature Publishing Group},
title = {{Automatic choroidal segmentation in OCT images using supervised deep learning methods}},
volume = {9},
year = {2019}
}
@article{Zheng2020,
abstract = {Accurate segmentation of choroidal thickness (CT) and vasculature is important to better analyze and understand the choroid-related ocular diseases. In this paper, we proposed and implemented a novel and practical method based on the deep learning algorithms, residual U-Net, to segment and quantify the CT and vasculature automatically. With limited training data and validation data, the residual U-Net was capable of identifying the choroidal boundaries as precise as the manual segmentation compared with an experienced operator. Then, the trained deep learning algorithms was applied to 217 images and six choroidal relevant parameters were extracted, we found high intraclass correlation coefficients (ICC) of more than 0.964 between manual and automatic segmentation methods. The automatic method also achieved great reproducibility with ICC greater than 0.913, indicating good consistency of the automatic segmentation method. Our results suggested the deep learning algorithms can accurately and efficiently segment choroid boundaries, which will be helpful to quantify the CT and vasculature.},
author = {Zheng, Gu and Jiang, Yanfeng and Shi, Ce and Miao, Hanpei and Yu, Xiangle and Wang, Yiyi and Chen, Sisi and Lin, Zhiyang and Wang, Weicheng and Lu, Fan and Shen, Meixiao},
doi = {10.1142/S1793545821400022},
file = {::},
issn = {17937205},
journal = {Journal of Innovative Optical Health Sciences},
keywords = {Deep learning,choroid,segmentation,swept-source optical coherence tomography},
month = {jan},
publisher = {World Scientific},
title = {{Deep learning algorithms to segment and quantify the choroidal thickness and vasculature in swept-source optical coherence tomography images}},
year = {2020}
}
@article{He2021,
abstract = {Optical coherence tomography (OCT) is a noninvasive cross-sectional imaging technology used to examine the retinal structure and pathology of the eye. Evaluating the thickness of the choroid using OCT images is of great interests for clinicians and researchers to monitor the choroidal thickness in many ocular diseases for diagnosis and management. However, manual segmentation and thickness profiling of choroid are time-consuming which lead to low efficiency in analyzing a large quantity of OCT images for swift treatment of patients. In this paper, an automatic segmentation approach based on convolutional neural network (CNN) classifier and l2-lq (0<q<1) fitter is presented to identify boundaries of the choroid and to generate thickness profile of the choroid from retinal OCT images. The method of detecting inner choroidal surface is motivated by its biological characteristics after light reflection, while the outer chorioscleral interface segmentation is transferred into a classification and fitting problem. The proposed method is tested in a data set of clinically obtained retinal OCT images with ground-truth marked by clinicians. Our numerical results demonstrate the effectiveness of the proposed approach to achieve stable and clinically accurate autosegmentation of the choroid.},
author = {He, Fang and Chun, Rachel Ka Man and Qiu, Zicheng and Yu, Shijie and Shi, Yun and To, Chi Ho and Chen, Xiaojun},
doi = {10.1155/2021/8882801},
file = {::},
issn = {17486718},
journal = {Computational and Mathematical Methods in Medicine},
publisher = {Hindawi Limited},
title = {{Choroid Segmentation of Retinal OCT Images Based on CNN Classifier and l2 - Lq Fitter}},
volume = {2021},
year = {2021}
}
@article{Maloca2021,
abstract = {Machine learning has greatly facilitated the analysis of medical data, while the internal operations usually remain intransparent. To better comprehend these opaque procedures, a convolutional neural network for optical coherence tomography image segmentation was enhanced with a Traceable Relevance Explainability (T-REX) technique. The proposed application was based on three components: ground truth generation by multiple graders, calculation of Hamming distances among graders and the machine learning algorithm, as well as a smart data visualization (‘neural recording'). An overall average variability of 1.75% between the human graders and the algorithm was found, slightly minor to 2.02% among human graders. The ambiguity in ground truth had noteworthy impact on machine learning results, which could be visualized. The convolutional neural network balanced between graders and allowed for modifiable predictions dependent on the compartment. Using the proposed T-REX setup, machine learning processes could be rendered more transparent and understandable, possibly leading to optimized applications.},
author = {Maloca, Peter M. and M{\"{u}}ller, Philipp L. and Lee, Aaron Y. and Tufail, Adnan and Balaskas, Konstantinos and Niklaus, Stephanie and Kaiser, Pascal and Suter, Susanne and Zarranz-Ventura, Javier and Egan, Catherine and Scholl, Hendrik P.N. and Schnitzer, Tobias K. and Singer, Thomas and Hasler, Pascal W. and Denk, Nora},
doi = {10.1038/s42003-021-01697-y},
file = {::},
issn = {23993642},
journal = {Communications Biology},
month = {dec},
number = {1},
publisher = {Nature Research},
title = {{Unraveling the deep learning gearbox in optical coherence tomography image segmentation towards explainable artificial intelligence}},
volume = {4},
year = {2021}
}
@article{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
eprint = {1505.04597},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:pdf},
month = {may},
title = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
url = {http://arxiv.org/abs/1505.04597},
year = {2015}
}

@article{Ronchetti2019,
abstract = {Monitoring subtle choroidal thickness changes in the human eye delivers insight into the pathogenesis of various ocular diseases such as myopia and helps planning their treatment. However, a thorough evaluation of detection-performance is challenging as a ground truth for comparison is not available. Alternatively, an artificial ground truth can be generated by averaging the manual expert segmentations. This makes the ground truth very sensitive to ambiguities due to different interpretations by the experts. In order to circumvent this limitation, we present a novel validation approach that operates independently from a ground truth and is uniquely based on the common agreement between algorithm and experts. Utilizing an appropriate index, we compare the joint agreement of several raters with the algorithm and validate it against manual expert segmentation. To illustrate this, we conduct an observational study and evaluate the results obtained using our previously published registration-based method. In addition, we present an adapted state-of-the-art evaluation method, where a paired t-test is carried out after leaving out the results of one expert at the time. Automated and manual detection were performed on a dataset of 90 OCT 3D-volume stack pairs of healthy subjects between 8 and 18 years of age from Asian urban regions with a high prevalence of myopia.},
author = {Ronchetti, Tiziano and Jud, Christoph and Maloca, Peter M. and Org{\"{u}}l, Selim and Giger, Alina T. and Meier, Christoph and Scholl, Hendrik P.N. and Chun, Rachel Ka Man and Liu, Quan and To, Chi Ho and Pova{\v{z}}ay, Boris and Cattin, Philippe C.},
doi = {10.1371/journal.pone.0218776},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronchetti et al. - 2019 - Statistical framework for validation without ground truth of choroidal thickness changes detection.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
month = {feb},
number = {6},
pmid = {31251762},
publisher = {Public Library of Science},
title = {{Statistical framework for validation without ground truth of choroidal thickness changes detection}},
volume = {14},
year = {2019}
}

@online{WikiChoroid,
  title = {Choroïde},
  year = 2021,
  url = {https://fr.wikipedia.org/wiki/Choro%C3%AFde#Choro%C3%AFde_et_photographie},
}


@article{Fabritius:09,
author = {Tapio Fabritius and Shuichi Makita and Masahiro Miura and Risto Myllyl\"{a} and Yoshiaki Yasuno},
journal = {Opt. Express},
keywords = {Image processing; Pattern recognition; Ophthalmology; Optical coherence tomography; Optical diagnostics for medicine; Image processing; Optic nerve; Optical coherence tomography; Retinal nerve fiber layer; Segmentation; Speckle noise},
number = {18},
pages = {15659--15669},
publisher = {OSA},
title = {Automated segmentation of the macula by optical coherence tomography},
volume = {17},
month = {Aug},
year = {2009},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-17-18-15659},
doi = {10.1364/OE.17.015659},
abstract = {This paper presents optical coherence tomography (OCT) signal intensity variation based segmentation algorithms for retinal layer identification. Its main ambition is to reduce the calculation time required by layer identification algorithms. Two algorithms, one for the identification of the internal limiting membrane (ILM) and the other for retinal pigment epithelium (RPE) identification are implemented to evaluate structural features of the retina. Using a 830 nm spectral domain OCT device, this paper demonstrates a segmentation method for the study of healthy and diseased eyes.},
}

@article {Brar597,
	author = {Brar, M and Bartsch, D-U G and Nigam, N and Mojana, F and Gomez, L and Cheng, L and Hedaya, J and Freeman, W R},
	title = {Colour versus grey-scale display of images on high-resolution spectral OCT},
	volume = {93},
	number = {5},
	pages = {597--602},
	year = {2009},
	doi = {10.1136/bjo.2008.146233},
	publisher = {BMJ Publishing Group Ltd},
	abstract = {Aim: To determine whether colour or grey-scale images from high-resolution spectral optical coherence tomography (OCT) are superior in visualising clinically important details of retinal structures.Methods: Patients with macular pathologies were imaged using spectral OCT (OTI, Toronto, Canada). Two reviewers independently analysed the retinal structures and pathologies and graded them on a four-point scale on the basis of the visibility. A third reviewer masked to the results then reviewed images where there was a different score for colour versus grey scale.Results: Statistical analysis showed the grey-scale image to be significantly better in visualising the details of epiretinal membrane, photoreceptor and retinal pigment epithelium layer morphology than the colour scale image (p = 0.00088{\textendash}0.0006). In 16.17\% of eyes, the colour image led to the false impression of photoreceptor disruption.Conclusion: Grey-scale images are qualitatively superior to the colour-scale images on high-resolution spectral OCT. Colour images can be misleading, as the displayed colours are false colours, and the observer may see a dramatic change in colour and interpret that as a large change in the OCT reflectivity.},
	issn = {0007-1161},
	URL = {https://bjo.bmj.com/content/93/5/597},
	eprint = {https://bjo.bmj.com/content/93/5/597.full.pdf},
	journal = {British Journal of Ophthalmology}
}

@article {choroidExpl,
	author = {Pomerleau, Jade},
	title = {Caractérisation des effets de l'hyperglycémie chronique dans la choroïde d'yeux diabétiques},
	year = {2016},
	abstract = {Purpose: Diabetes is an important public health problem, and diabetic retinopathy (DR) is the most common ocular complication. Some studies indicate that the choroid of diabetic patients is affected without apparent signs of DR. Our hypothesis is that the increase of oxidative stress linked to chronic hyperglycemia affects the choroidal function at an early stage of DR. We propose to study glycolysis, mitochondrial metabolism, nitrosative stress and DNA methylation as well as to characterize histological modifications in the diabetic choroid. Methods: The expression of genes/proteins involved in glycolysis, mitochondrial metabolism and production of nitric oxide was compared by DNA microarray and Western blot between healthy and diabetic choroids. Levels of DNA methylation and hydroxymethylation were quantified by slot blot and HPLC-MS/MS in these tissues. Finally, eye sections from healthy or diabetic donors with non-proliferative (NPDR) or proliferative (PDR) DR were colored with Masson’s trichrome and Weigert’s stains. Choroid and Bruch’s membrane thickness, as well as density and diameter of choroidal vessels were analyzed. Results: Our results show a deregulation of the transcriptome of the diabetic choroid, but little variation in the protein expression of validated targets. The global DNA methylation level was similar between diabetic and healthy donors. Our histological analyses demonstrate a thinning of the choroid, and a degeneration of choriocapillaris and choroid veins in diabetic donors with PDR. Conclusions: The study of the choroid is important since damages to this tissue have serious effects on the retinal function. Identification of targets in the choroid opens new perspectives for a preventive treatment of DR.},
	URL = {https://corpus.ulaval.ca/jspui/handle/20.500.11794/27049},
	eprint = {https://corpus.ulaval.ca/jspui/bitstream/20.500.11794/27049/1/32823.pdf},
}

@article {CNNSpatialLocation,
	author = {Osman Semih Kayhan, Jan C. van Gemert},
	title = {Colour versus grey-scale display of images on high-resolution spectral OCT},
	year = {2020},
	publisher = {The Computer Vision Foundation},
	abstract = {In this paper we challenge the common assumption that convolutional layers in modern CNNs are translation invariant. We show that CNNs can and will exploit the absolute spatial location by learning filters that respond exclusively to particular absolute locations by exploiting image boundary effects. Because modern CNNs filters have a huge receptive field, these boundary effects operate even far from the image boundary, allowing the network to exploit absolute spatial location all over the image. We give a simple solution to remove spatial location encoding which improves translation invariance and thus gives a stronger visual inductive bias which particularly benefits small data sets. We broadly demonstrate these benefits on several architectures and various applications such as image classification, patch matching, and two video classification datasets.},
	URL = {},
	eprint = {https://openaccess.thecvf.com/content_CVPR_2020/papers/Kayhan_On_Translation_Invariance_in_CNNs_Convolutional_Layers_Can_Exploit_Absolute_CVPR_2020_paper.pdf}
}


@book{DIDLBook,
author = {Aston Zhang Zachary C Lipton. Mu Li Alexander J. Smola},
title = {Dive into Deep Learning},
url = {https://d2l.ai/},
volume = {10554},
year = {2021}
}

@article{Garrido2014,
   abstract = {Background: Optical coherence tomography (OCT) is an invaluable diagnostic tool for the detection and follow-up of retinal pathology in patients and experimental disease models. However, as morphological structures and layering in health as well as their alterations in disease are complex, segmentation procedures have not yet reached a satisfactory level of performance. Therefore, raw images and qualitative data are commonly used in clinical and scientific reports. Here, we assess the value of OCT reflectivity profiles as a basis for a quantitative characterization of the retinal status in a cross-species comparative study. Methods: Spectral-Domain Optical Coherence Tomography (OCT), confocal Scanning-La-ser Ophthalmoscopy (SLO), and Fluorescein Angiography (FA) were performed in mice (Mus musculus), gerbils (Gerbillus perpadillus), and cynomolgus monkeys (Macaca fascicularis) using the Heidelberg Engineering Spectralis system, and additional SLOs and FAs were obtained with the HRA I (same manufacturer). Reflectivity profiles were extracted from 8-bit greyscale OCT images using the ImageJ software package (http://rsb.info.nih.gov/ij/). Results: Reflectivity profiles obtained from OCT scans of all three animal species correlated well with ex vivo histomorphometric data. Each of the retinal layers showed a typical pattern that varied in relative size and degree of reflectivity across species. In general, plexiform layers showed a higher level of reflectivity than nuclear layers. A comparison of reflectivity profiles from specialized retinal regions (e.g. visual streak in gerbils, fovea in non-human primates) with respective regions of human retina revealed multiple similarities. In a model of Retinitis Pigmentosa (RP), the value of reflectivity profiles for the follow-up of therapeutic interventions was demonstrated. Conclusions: OCT reflectivity profiles provide a detailed, quantitative description of retinal layers and structures including specialized retinal regions. Our results highlight the potential of this approach in the long-term follow-up of therapeutic strategies. © 2014 Garcia Garrido et al.},
   author = {Marina Garcia Garrido and Susanne C. Beck and Regine Mühlfriedel and Sylvie Julien and Ulrich Schraermeyer and Mathias W. Seeliger},
   doi = {10.1371/journal.pone.0100080},
   issn = {19326203},
   issue = {6},
   journal = {PLoS ONE},
   month = {6},
   pmid = {24927180},
   publisher = {Public Library of Science},
   title = {Towards a quantitative OCT image analysis},
   volume = {9},
   year = {2014},
}


@misc{Willdeman2016,
        title = {What is OCT and how can it help ophthalmologists acquire high resolution information on ocular tissue?},
        year = {2016},
        author = {Wildeman et al.},
        howpublished={Available on: \url{https://www.leica-microsystems.com/science-lab/what-is-oct-and-how-can-it-help-ophthalmologists-acquire-high-resolution-information-on-ocular-tissue/}},
        note = {Accessed: 2021-17-05}
     
    }

@Article{Jiang2018,
author={Jiang, Jing
and Liu, Yan
and Chen, Yingchao
and Ma, Bo
and Qian, Yiwen
and Zhang, Zhenzhen
and Zhu, Dongqing
and Wang, Zhiliang
and Xu, Xiaofang},
title={Analysis of Changes in Retinal Thickness in Type 2 Diabetes without Diabetic Retinopathy},
journal={Journal of Diabetes Research},
year={2018},
month={Feb},
day={25},
publisher={Hindawi},
volume={2018},
pages={3082893},
issn={2314-6745},
doi={10.1155/2018/3082893},
url={https://doi.org/10.1155/2018/3082893}
}

@article{DENHAAN2017162,
author = {Den Haan, J
and Frank D. Verbraak 
and Pieter Jelle Visser 
and Femke H. Bouwman},
title = {Retinal thickness in Alzheimer's disease: A systematic review and meta-analysis},
journal = {Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
volume = {6},
pages = {162 - 170},
year = {2017},
issn = {2352-8729},
howpublished = {available on: \url{http://www.sciencedirect.com/science/article/pii/S2352872916300793}},

}

@incollection{MACNAIR2015343,
title = "Chapter Twenty - Neuroinflammation in Glaucoma and Optic Nerve Damage",
editor = "J. Fielding Hejtmancik and John M. Nickerson",
series = "Progress in Molecular Biology and Translational Science",
publisher = "Academic Press",
volume = "134",
pages = "343 - 363",
year = "2015",
booktitle = "Molecular Biology of Eye Disease",
issn = "1877-1173",
doi = "https://doi.org/10.1016/bs.pmbts.2015.06.010",
url = "http://www.sciencedirect.com/science/article/pii/S187711731500112X",
author = "Caitlin E. {Mac Nair} and Robert W. Nickells",
keywords = "Retinal ganglion cells, Immune privilege, Microglia, Müller cells, Astrocytes, Glaucoma, Neuroinflammation",
abstract = "Glaucoma is a group of optic neuropathies characterized by the degeneration of retinal ganglion cell axons and somas, ultimately preventing light signals in the retina from reaching the brain. Glaucoma is a leading cause of blindness in the world, and treatment options for patients remain limited and minimally efficacious. A number of mechanisms have been linked to glaucomatous pathophysiology. A leading role is now attributed to neuroinflammatory conditions generated by the resident innate immune cells in the optic nerve and retina. Since the eye is immune privileged, the adaptation of these innate immune cells, termed glia, is crucial following trauma. In this chapter, we discuss the mechanisms associated with normal glial function in a healthy eye, and how changes in glial activation can contribute to the process of glaucomatous neurodegeneration in both the optic nerve and retina."
}

@article{BOOIJ20101,
title = "The dynamic nature of Bruch's membrane",
journal = "Progress in Retinal and Eye Research",
volume = "29",
number = "1",
pages = "1 - 18",
year = "2010",
issn = "1350-9462",
doi = "https://doi.org/10.1016/j.preteyeres.2009.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S1350946209000597",
author = "J.C. Booij and D.C. Baas and J. Beisekeeva and T.G.M.F. Gorgels and A.A.B. Bergen",
keywords = "Bruch's membrane, Drusen, AMD, Aging, Molecular composition, Inner collagenous layer, Outer collagenous layer, Elastin layer, Basal membrane",
abstract = "Bruch's membrane (BM) is a unique pentalaminar structure, which is strategically located between the retinal pigment epithelium (RPE) and the fenestrated choroidal capillaries of the eye. BM is an elastin- and collagen-rich extracellular matrix that acts as a molecular sieve. BM partly regulates the reciprocal exchange of biomolecules, nutrients, oxygen, fluids and metabolic waste products between the retina and the general circulation. Accumulating evidence suggests that the molecular, structural and functional properties of BM are dependent on age, genetic constitution, environmental factors, retinal location and disease state. As a result, part of the properties of BM are unique to each human individual at a given age, and therefore uniquely affect the development of normal vision and ocular disease. The changes occurring in BM with age include increased calcification of elastic fibres, increased cross-linkage of collagen fibres and increased turnover of glycosaminoglycans. In addition, advanced glycation end products (AGEs) and fat accumulate in BM. These age-related changes may not only influence the normal age-related health of photoreceptor cells, but also the onset and progression of diseases like retinitis pigmentosa (RP) and age-related macular degeneration (AMD). Undoubtedly, BM is the site of drusen development. Confluent drusen and uncontrolled activation of the complement cascade are most likely the first signs of AMD. Furthermore, the nature of adhesive interactions between the RPE and BM are instrumental in the development of retinal detachments and proliferative retinal disease. Finally, BM is passively or actively involved in a range of other retinal disorders such as Pseudoxanthoma elasticum (PXE), Sorsby's Fundus Dystrophy and Malattia Leventinese. Here, we review the dynamic nature of Bruch's membrane, from molecule to man, during development, aging and disease. We propose a simple and straightforward nomenclature for BM deposits. Finally, we attempt to correlate recently published mRNA expression profiles of the RPE and choroid with molecular, structural and functional properties of BM. Our review may shed light on the complex involvement of BM in retinal pathology, notably age-related macular degeneration."
}

@book{snell1998,
   author = {Snell R. S. and  Lemp M. A.},
   edition = {Second Edition},
   publisher = {Blackwell Science},
   title = {Clinical Anatomy of the Eye},
   year = {1998},
}

@book_section{Rhoades2017,
   author = {William Rhoades and Leila Kump and Eyal Margalit},
   journal = {Neuroimmune Pharmacology},
   pages = {39-54},
   title = {Anterior Chamber and Retina (Structure, Function and Immunology)},
   year = {2017},
}

@misc{eyeanatomy-pic,
        title = {Anatomy of the Eye},
        year = {2021},
        author = {Armenian Eye Care Project},
        howpublished={Available on: \url{https://eyecareproject.com/about-the-eye/how-the-eye-works/anatomy-of-the-eye/}},
        note = {Accessed: 2021-17-05}
     
    }

@book{purves2001,
      title     = {Neuroscience},
      author    = {Purves D and Augustine GJ and Fitzpatrick D and et al},
      year      = {2001},
      publisher = {Sinauer Associates},
      note = {Available from \url{https://www.ncbi.nlm.nih.gov/books/NBK10885/}}
}

@Inbook{Meek2008,
author="Meek, K.M.",
editor="Fratzl, Peter",
title="The Cornea and Sclera",
bookTitle="Collagen: Structure and Mechanics",
year="2008",
publisher="Springer US",
address="Boston, MA",
pages="359--396",
abstract="The cornea and sclera make up the outer tunic of the eye. Each is a connective tissue containing collagen fibrils embedded in a proteoglycan-rich extrafibrillar matrix, but whereas the cornea is uniquely transparent, the sclera is totally opaque. Both tissues require strength to maintain the excess pressure within the eye and to resist external knocks and the forces applied by the extraocular muscles during eye movement. This mechanical strength is provided by the deposition of collagen in a lamellar structure, where the lamellae run parallel to the surface of the tissue rather than through its thickness. The cornea is the main refractive element in the eye's optical system, and it transmits over 90{\%} of the incident light at visible wavelengths. Transparency is achieved because, at the nanoscopic level, the corneal collagen fibrils within the lamellae have a small, uniform diameter and are positioned with respect to each other with a high degree of lateral order. This exquisite arrangement causes destructive interference of scattered light and constructive interference of directly transmitted light throughout the visible wavelengths. As a lens, the cornea also has to be precisely curved, almost spherical near the visual axis but flattening in the periphery. Although the basis of this contour is not fully understood, corneal shape is likely achieved by the arrangement of the collagen at the microscopic level, and it is therefore not surprising that the lamellae have different preferential orientations centrally and peripherally.",
isbn="978-0-387-73906-9",
doi="10.1007/978-0-387-73906-9_13",
url="https://doi.org/10.1007/978-0-387-73906-9_13"
}

@article {SoftMaxClassification,
	author = {Fei Gao and Bing Li and Lei Chen and Zhongyu Shang and Xiang Wei and Chen He},
	title = {A softmax classifier for high-precision classification of ultrasonic similar signals},
	year = {2021},
	doi = {10.1016/j.ultras.2020.106344},
	publisher = {SciencDirect},
	abstract = {High precision classification of ultrasonic signals is helpful to improve the identification and evaluation accuracy for detecting defects. In the previous research, the deep neural network (DNN) has been used to classify the signal with obvious differences. But for different defects of the same depth, or when the defect position is close, the ultrasonic A-scan signal curve is very similar, causing the classification accuracy not high enough. In this paper, an optimized softmax classifier is proposed based on the traditional softmax classifier, and the convolution neural network (CNN) framework is built, which can achieve the accurate classification of signals with similar curves. Through a comparative experiment, the performance of the proposed classifier is evaluated from the loss curve decline rate, classification accuracy and feature visualization. The results show that the classifier has high classification accuracy and strong robustness.},
	URL = {https://www.sciencedirect.com/science/article/pii/S0041624X20302730#b0105},
	eprint = {https://reader.elsevier.com/reader/sd/pii/S0041624X20302730?token=DD1BD2E485417B48310FA6F562FE3DF76BBABFCC883F5CD86EBC592212B80CB47EFE9DA523118039B3AB14476CA45B0B&originRegion=eu-west-1&originCreation=20210518145602},
}


@article {DFTPooling,
	author = {Jongbin Ryu, Ming-Hsuan Yang, Jongwoo Lim},
	title = {DFT-based Transformation Invariant Pooling Layer for Visual Classification},
	year = {2018},
	publisher = {The Computer Vision Foundation},
	abstract = {We propose a novel discrete Fourier transform-based pooling layer for convolutional neural networks. The DFT magnitude pooling replaces the traditional max/average pooling layer between the convolution and fully-connected layers to retain translation invariance and shape preserving (aware of shape difference) properties based on the shift theorem of the Fourier transform. Thanks to the ability to handle image misalignment while keeping important structural information in the pooling stage, the DFT magnitude pooling improves the classification accuracy significantly. In addition, we propose the DFT+ method for ensemble networks using the middle convolution layer outputs. The proposed methods are extensively evaluated on various classification tasks using the ImageNet, CUB 2010-2011, MIT Indoors, Caltech 101, FMD and DTD datasets. The AlexNet, VGG-VD 16, Inception-v3, and ResNet are used as the base networks, upon which DFT and DFT+ methods are implemented. Experimental results show that the proposed methods improve the classification performance in all networks and datasets.},
	URL = {https://openaccess.thecvf.com/content_ECCV_2018/html/Jongbin_Ryu_DFT-based_Transformation_Invariant_ECCV_2018_paper.html},
	eprint = {https://openaccess.thecvf.com/content_ECCV_2018/papers/Jongbin_Ryu_DFT-based_Transformation_Invariant_ECCV_2018_paper.pdf}
}


