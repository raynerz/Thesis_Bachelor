@techreport{Cochrane2005,
abstract = {Figure out the one central and novel contribution of your paper. Write this down in one paragraph. As with all your writing, this must be concrete. Don't write "I analyzed data on executive compensation and found many interesting results." Explain what the central results are. For example, Fama and French 1992 start their abstract with: "Two easily measured variables, size and book-to-market equity, combine to capture the cross-sectional variation in average stock returns associated with market , size, leverage, book-to-market equity, and earnings-price ratios." Distilling your one central contribution will take some thought. It will cause some pain, because you will start to realize how much you're going to have to throw out. Once you do it, though, you're in a much better position to focus the paper on that one contribution, and help readers to get it quickly. Your readers are busy and impatient. No reader will ever read the whole thing from start to nish. Readers skim. You have to make it easy for them to skim. Most readers want to know your basic result. Only a few care how it is digerent from others. Only a few care if it holds up with digerent variable denitions, digerent instrument sets, etc. Organize the paper in "triangular" or "newspaper" style, not in "joke" or "novel" style. Notice how newspapers start with the most important part, then ll in background later for the readers who kept going and want more details. A good joke or a mystery novel has a long windup to the nal punchline. Don't write papers like that-put the punchline right up front and then slowly explain the joke. Readers don't stick around to nd the punchline in Table 12. The vast majority of Ph.D. student papers and workshop presentations (not all by students !) get this exactly wrong, and we never really nd out what the contribution of the paper is until the last page, the last table, and the last 5 minutes of the seminar. A good paper is not a travelogue of your search process. We don't care how you came to gure out the right answer. We don't care about the hundreds of things you tried that did not work. Save it for your memoirs. Abstract Most journals allow 100-150 words. Obey this limit now. The main function of the abstract is to communicate the one central and novel contribution, which you just gured out. You should not mention other literature in the abstract. Like everything else, the abstract must be concrete. Say what you nd, not what you look for. Here too, don't write "data are analyzed, theorems are proved, discussion is made.."},
author = {Cochrane, John H},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cochrane - 2005 - Writing Tips for Ph. D. Students.pdf:pdf},
title = {{Writing Tips for Ph. D. Students}},
url = {http://gsbwww.uchicago.edu/fac/john.cochrane/research/Papers/},
year = {2005}
}
@article{Muller2021,
abstract = {Background: The increased availability and usage of modern medical imaging induced a strong need for automatic medical image segmentation. Still, current image segmentation platforms do not provide the required functionalities for plain setup of medical image segmentation pipelines. Already implemented pipelines are commonly standalone software, optimized on a specific public data set. Therefore, this paper introduces the open-source Python library MIScnn. Implementation: The aim of MIScnn is to provide an intuitive API allowing fast building of medical image segmentation pipelines including data I/O, preprocessing, data augmentation, patch-wise analysis, metrics, a library with state-of-the-art deep learning models and model utilization like training, prediction, as well as fully automatic evaluation (e.g. cross-validation). Similarly, high configurability and multiple open interfaces allow full pipeline customization. Results: Running a cross-validation with MIScnn on the Kidney Tumor Segmentation Challenge 2019 data set (multi-class semantic segmentation with 300 CT scans) resulted into a powerful predictor based on the standard 3D U-Net model. Conclusions: With this experiment, we could show that the MIScnn framework enables researchers to rapidly set up a complete medical image segmentation pipeline by using just a few lines of code. The source code for MIScnn is available in the Git repository: https://github.com/frankkramer-lab/MIScnn.},
archivePrefix = {arXiv},
arxivId = {1910.09308},
author = {M{\"{u}}ller, Dominik and Kramer, Frank},
doi = {10.1186/s12880-020-00543-7},
eprint = {1910.09308},
file = {::},
issn = {14712342},
journal = {BMC Medical Imaging},
keywords = {Biomedical image segmentation,Computer aided diagnosis,Deep learning,Medical image analysis,Open-source framework,U-Net},
month = {dec},
number = {1},
pmid = {33461500},
publisher = {BioMed Central Ltd},
title = {{MIScnn: a framework for medical image segmentation with convolutional neural networks and deep learning}},
volume = {21},
year = {2021}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
eprint = {1512.03385},
file = {::},
month = {dec},
title = {{Deep Residual Learning for Image Recognition}},
url = {http://arxiv.org/abs/1512.03385},
year = {2015}
}
@article{Lu2017,
abstract = {The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-$2$) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-$(n+4)$ ReLU networks, where $n$ is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-$n$ ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth is more effective than width for the expressiveness of ReLU networks.},
archivePrefix = {arXiv},
arxivId = {1709.02540},
author = {Lu, Zhou and Pu, Hongming and Wang, Feicheng and Hu, Zhiqiang and Wang, Liwei},
eprint = {1709.02540},
file = {::},
month = {sep},
title = {{The Expressive Power of Neural Networks: A View from the Width}},
url = {http://arxiv.org/abs/1709.02540},
year = {2017}
}
@techreport{Zhang2021,
author = {Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J},
file = {::},
title = {{Dive into Deep Learning Release 0.16.2}},
year = {2021}
}
@misc{Roy2017,
abstract = {Optical coherence tomography \(OCT\) is used for non-invasive diagnosis of diabetic macular edema assessing the retinal layers. In this paper, we propose a new fully convolutional deep architecture, termed ReLayNet, for end-to-end segmentation of retinal layers and fluid masses in eye OCT scans. ReLayNet uses a contracting path of convolutional blocks \(encoders\) to learn a hierarchy of contextual features, followed by an expansive path of convolutional blocks \(decoders\) for semantic segmentation. ReLayNet is trained to optimize a joint loss function comprising of weighted logistic regression and Dice overlap loss. The framework is validated on a publicly available benchmark dataset with comparisons against five state-of-the-art segmentation methods including two deep learning based approaches to substantiate its effectiveness.},
archivePrefix = {arXiv},
arxivId = {1704.02161},
author = {Roy, Abhijit Guha and Conjeti, Sailesh and Karri, Sri Phani Krishna and Sheet, Debdoot and Katouzian, Amin and Wachinger, Christian and Navab, Nassir},
booktitle = {arXiv},
doi = {10.1364/boe.8.003627},
eprint = {1704.02161},
file = {::},
issn = {23318422},
month = {apr},
pmid = {28856040},
publisher = {arXiv},
title = {{ReLaynet: Retinal layer and fluid segmentation of macular optical coherence tomography using fully convolutional networks}},
year = {2017}
}
@article{Maloca2019,
abstract = {Purpose To benchmark the human and machine performance of spectral-domain (SD) and sweptsource (SS) optical coherence tomography (OCT) image segmentation, i.e., pixel-wise classification, for the compartments vitreous, retina, choroid, sclera. Methods A convolutional neural network (CNN) was trained on OCT B-scan images annotated by a senior ground truth expert retina specialist to segment the posterior eye compartments. Independent benchmark data sets (30 SDOCT and 30 SSOCT) were manually segmented by three classes of graders with varying levels of ophthalmic proficiencies. Nine graders contributed to benchmark an additional 60 images in three consecutive runs. Inter-human and intra-human class agreement was measured and compared to the CNN results. Results The CNN training data consisted of a total of 6210 manually segmented images derived from 2070 B-scans (1046 SDOCT and 1024 SSOCT; 630 C-Scans). The CNN segmentation revealed a high agreement with all grader groups. For all compartments and groups, the mean Intersection over Union (IOU) score of CNN compartmentalization versus group graders' compartmentalization was higher than the mean score for intra-grader group comparison. Conclusion The proposed deep learning segmentation algorithm (CNN) for automated eye compartment segmentation in OCT B-scans (SDOCT and SSOCT) is on par with manual segmentations by human graders.},
author = {Maloca, Peter M. and Lee, Aaron Y. and {De Carvalho}, Emanuel R. and Okada, Mali and Fasler, Katrin and Leung, Irene and H{\"{o}}rmann, Beat and Kaiser, Pascal and Suter, Susanne and Hasler, Pascal W. and Zarranz-Ventura, Javier and Egan, Catherine and Heeren, Tjebo F.C. and Balaskas, Konstantinos and Tufail, Adnan and Scholl, Hendrik P.N.},
doi = {10.1371/journal.pone.0220063},
file = {::},
issn = {19326203},
journal = {PLoS ONE},
month = {aug},
number = {8},
pmid = {31419240},
publisher = {Public Library of Science},
title = {{Validation of automated artificial intelligence segmentation of optical coherence tomography images}},
volume = {14},
year = {2019}
}

@article{Alonso-Caneiro2013,
abstract = {The assessment of choroidal thickness from optical coherence tomography (OCT) images of the human choroid is an important clinical and research task, since it provides valuable information regarding the eye's normal anatomy and physiology, and changes associated with various eye diseases and the development of refractive error. Due to the time consuming and subjective nature of manual image analysis, there is a need for the development of reliable objective automated methods of image segmentation to derive choroidal thickness measures. However, the detection of the two boundaries which delineate the choroid is a complicated and challenging task, in particular the detection of the outer choroidal boundary, due to a number of issues including: (i) the vascular ocular tissue is non-uniform and rich in non-homogeneous features, and (ii) the boundary can have a low contrast. In this paper, an automatic segmentation technique based on graph-search theory is presented to segment the inner choroidal boundary (ICB) and the outer choroidal boundary (OCB) to obtain the choroid thickness profile from OCT images. Before the segmentation, the B-scan is pre-processed to enhance the two boundaries of interest and to minimize the artifacts produced by surrounding features. The algorithm to detect the ICB is based on a simple edge filter and a directional weighted map penalty, while the algorithm to detect the OCB is based on OCT image enhancement and a dual brightness probability gradient. The method was tested on a large data set of images from a pediatric (1083 B-scans) and an adult (90 B-scans) population, which were previously manually segmented by an experienced observer. The results demonstrate the proposed method provides robust detection of the boundaries of interest and is a useful tool to extract clinical data.},
author = {Alonso-Caneiro, David and Read, Scott A. and Collins, Michael J.},
doi = {10.1364/boe.4.002795},
file = {::},
issn = {2156-7085},
journal = {Biomedical Optics Express},
month = {dec},
number = {12},
pages = {2795},
pmid = {24409381},
publisher = {The Optical Society},
title = {{Automatic segmentation of choroidal thickness in optical coherence tomography}},
volume = {4},
year = {2013}
}

@inproceedings{Ronchetti2018,
abstract = {Macular Telangiectasia Type 2 (MacTel2) is a disease of the retina leading to a gradual deterioration of central vision. At the onset of the disease a good visual acuity is present, which declines as the disease progresses to cause reading difficulties. In this paper, we present new insights on the vascular changes in MacTel2. We investigated whether MacTel2 progression correlates to changes in the thickness of the choroid. For this purpose, we apply a recently published registration-based approach to detect deviations in the choroid on a dataset of 45 MacTel2 patients. Between 2012 and 2016 these subjects and a control group were measured twice within variable intervals of time in the Moorfields Eye Hospital in the MacTel Natural History Observation and Registry Study. Our results show that in the MacTel2 group the thickness of the choroid increased while in the control group a decrease was noted. Manual expert segmentation and an automated state-of-the-art method were used to validate the results.},
author = {Ronchetti, Tiziano and Maloca, Peter and de Carvalho, Emanuel Ramos and Heeren, Tjebo F.C. and Balaskas, Konstantinos and Tufail, Adnan and Egan, Catherine and Okada, Mali and Org{\"{u}}l, Selim and Jud, Christoph and Cattin, Philippe C.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-00949-6_36},
file = {::},
isbn = {9783030009489},
issn = {16113349},
keywords = {Choroidal thickness changes,Macular Telangiectasia Type 2,Piecewise rigid registration},
pages = {303--309},
publisher = {Springer Verlag},
title = {{Feasibility Study of Subfoveal Choroidal Thickness Changes in Spectral-Domain Optical Coherence Tomography Measurements of Macular Telangiectasia Type 2}},
volume = {11039 LNCS},
year = {2018}
}

@book{Ronchetti2017,
address = {Cham},
author = {Ronchetti, Tiziano and Maloca, Peter and Jud, Christoph and Meier, Christoph and Et al.},
doi = {10.1007/978-3-319-67561-9},
editor = {Cardoso, M. Jorge and Arbel, Tal and Melbourne, Andrew and Bogunovic, Hrvoje and Moeskops, Pim and Chen, Xinjian and Schwartz, Ernst and Garvin, Mona and Robinson, Emma and Trucco, Emanuele and Ebner, Michael and Xu, Yanwu and Makropoulos, Antonios and Desjardin, Adrien and Vercauteren, Tom},
file = {::},
isbn = {978-3-319-67560-2},
publisher = {Springer International Publishing},
series = {Lecture Notes in Computer Science},
title = {{Fetal, Infant and Ophthalmic Medical Image Analysis}},
url = {http://link.springer.com/10.1007/978-3-319-67561-9},
volume = {10554},
year = {2017}
}
@techreport{Fabritius2001,
abstract = {This paper presents optical coherence tomography (OCT) signal intensity variation based segmentation algorithms for retinal layer identification. Its main ambition is to reduce the calculation time required by layer identification algorithms. Two algorithms, one for the identification of the internal limiting membrane (ILM) and the other for retinal pigment epithelium (RPE) identification are implemented to evaluate structural features of the retina. Using a 830 nm spectral domain OCT device, this paper demonstrates a segmentation method for the study of healthy and diseased eyes.},
author = {Fabritius, Tapio and Makita, Shuichi and Miura, Masahiro and Myllyl{\"{a}}, Risto and Yasuno, Yoshiaki and Koozekanani, D and Boyer, K and Roberts, C and Ishikawa, H and Stein, DM and Wollstein, G and Beaton, S and Fujimoto, JG and Schuman, JS and Szkulmowski, M and Wojtkowski, M and Sikorski, B and Bajraszewski, T and Srinivasan, V J and Szkulmowska, A and Kaluzny, J J and Fujimoto, J G and Kowalczyk, A},
booktitle = {Investigative Ophthalmol. Visual Scie},
file = {::},
pages = {2012--2017},
title = {{Image processing; (100.5010) Pattern recognition and feature ex-traction; (170.4470) Ophthalmology; (170.4500) Optical coherence tomography; (170.4580) Optical diagnostics for medicine}},
volume = {20},
year = {2001}
}
@article{Kugelman2019,
abstract = {The analysis of the choroid in the eye is crucial for our understanding of a range of ocular diseases and physiological processes. Optical coherence tomography (OCT) imaging provides the ability to capture highly detailed cross-sectional images of the choroid yet only a very limited number of commercial OCT instruments provide methods for automatic segmentation of choroidal tissue. Manual annotation of the choroidal boundaries is often performed but this is impractical due to the lengthy time taken to analyse large volumes of images. Therefore, there is a pressing need for reliable and accurate methods to automatically segment choroidal tissue boundaries in OCT images. In this work, a variety of patch-based and fully-convolutional deep learning methods are proposed to accurately determine the location of the choroidal boundaries of interest. The effect of network architecture, patch-size and contrast enhancement methods was tested to better understand the optimal architecture and approach to maximize performance. The results are compared with manual boundary segmentation used as a ground-truth, as well as with a standard image analysis technique. Results of total retinal layer segmentation are also presented for comparison purposes. The findings presented here demonstrate the benefit of deep learning methods for segmentation of the chorio-retinal boundary analysis in OCT images.},
author = {Kugelman, Jason and Alonso-Caneiro, David and Read, Scott A. and Hamwood, Jared and Vincent, Stephen J. and Chen, Fred K. and Collins, Michael J.},
doi = {10.1038/s41598-019-49816-4},
file = {::},
issn = {20452322},
journal = {Scientific Reports},
month = {dec},
number = {1},
pmid = {31527630},
publisher = {Nature Publishing Group},
title = {{Automatic choroidal segmentation in OCT images using supervised deep learning methods}},
volume = {9},
year = {2019}
}
@article{Zheng2020,
abstract = {Accurate segmentation of choroidal thickness (CT) and vasculature is important to better analyze and understand the choroid-related ocular diseases. In this paper, we proposed and implemented a novel and practical method based on the deep learning algorithms, residual U-Net, to segment and quantify the CT and vasculature automatically. With limited training data and validation data, the residual U-Net was capable of identifying the choroidal boundaries as precise as the manual segmentation compared with an experienced operator. Then, the trained deep learning algorithms was applied to 217 images and six choroidal relevant parameters were extracted, we found high intraclass correlation coefficients (ICC) of more than 0.964 between manual and automatic segmentation methods. The automatic method also achieved great reproducibility with ICC greater than 0.913, indicating good consistency of the automatic segmentation method. Our results suggested the deep learning algorithms can accurately and efficiently segment choroid boundaries, which will be helpful to quantify the CT and vasculature.},
author = {Zheng, Gu and Jiang, Yanfeng and Shi, Ce and Miao, Hanpei and Yu, Xiangle and Wang, Yiyi and Chen, Sisi and Lin, Zhiyang and Wang, Weicheng and Lu, Fan and Shen, Meixiao},
doi = {10.1142/S1793545821400022},
file = {::},
issn = {17937205},
journal = {Journal of Innovative Optical Health Sciences},
keywords = {Deep learning,choroid,segmentation,swept-source optical coherence tomography},
month = {jan},
publisher = {World Scientific},
title = {{Deep learning algorithms to segment and quantify the choroidal thickness and vasculature in swept-source optical coherence tomography images}},
year = {2020}
}
@article{He2021,
abstract = {Optical coherence tomography (OCT) is a noninvasive cross-sectional imaging technology used to examine the retinal structure and pathology of the eye. Evaluating the thickness of the choroid using OCT images is of great interests for clinicians and researchers to monitor the choroidal thickness in many ocular diseases for diagnosis and management. However, manual segmentation and thickness profiling of choroid are time-consuming which lead to low efficiency in analyzing a large quantity of OCT images for swift treatment of patients. In this paper, an automatic segmentation approach based on convolutional neural network (CNN) classifier and l2-lq (0<q<1) fitter is presented to identify boundaries of the choroid and to generate thickness profile of the choroid from retinal OCT images. The method of detecting inner choroidal surface is motivated by its biological characteristics after light reflection, while the outer chorioscleral interface segmentation is transferred into a classification and fitting problem. The proposed method is tested in a data set of clinically obtained retinal OCT images with ground-truth marked by clinicians. Our numerical results demonstrate the effectiveness of the proposed approach to achieve stable and clinically accurate autosegmentation of the choroid.},
author = {He, Fang and Chun, Rachel Ka Man and Qiu, Zicheng and Yu, Shijie and Shi, Yun and To, Chi Ho and Chen, Xiaojun},
doi = {10.1155/2021/8882801},
file = {::},
issn = {17486718},
journal = {Computational and Mathematical Methods in Medicine},
publisher = {Hindawi Limited},
title = {{Choroid Segmentation of Retinal OCT Images Based on CNN Classifier and l2 - Lq Fitter}},
volume = {2021},
year = {2021}
}
@article{Maloca2021,
abstract = {Machine learning has greatly facilitated the analysis of medical data, while the internal operations usually remain intransparent. To better comprehend these opaque procedures, a convolutional neural network for optical coherence tomography image segmentation was enhanced with a Traceable Relevance Explainability (T-REX) technique. The proposed application was based on three components: ground truth generation by multiple graders, calculation of Hamming distances among graders and the machine learning algorithm, as well as a smart data visualization (‘neural recording'). An overall average variability of 1.75% between the human graders and the algorithm was found, slightly minor to 2.02% among human graders. The ambiguity in ground truth had noteworthy impact on machine learning results, which could be visualized. The convolutional neural network balanced between graders and allowed for modifiable predictions dependent on the compartment. Using the proposed T-REX setup, machine learning processes could be rendered more transparent and understandable, possibly leading to optimized applications.},
author = {Maloca, Peter M. and M{\"{u}}ller, Philipp L. and Lee, Aaron Y. and Tufail, Adnan and Balaskas, Konstantinos and Niklaus, Stephanie and Kaiser, Pascal and Suter, Susanne and Zarranz-Ventura, Javier and Egan, Catherine and Scholl, Hendrik P.N. and Schnitzer, Tobias K. and Singer, Thomas and Hasler, Pascal W. and Denk, Nora},
doi = {10.1038/s42003-021-01697-y},
file = {::},
issn = {23993642},
journal = {Communications Biology},
month = {dec},
number = {1},
publisher = {Nature Research},
title = {{Unraveling the deep learning gearbox in optical coherence tomography image segmentation towards explainable artificial intelligence}},
volume = {4},
year = {2021}
}
@article{Ronneberger2015,
abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
archivePrefix = {arXiv},
arxivId = {1505.04597},
author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
eprint = {1505.04597},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronneberger, Fischer, Brox - 2015 - U-Net Convolutional Networks for Biomedical Image Segmentation.pdf:pdf},
month = {may},
title = {{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
url = {http://arxiv.org/abs/1505.04597},
year = {2015}
}

@article{Ronchetti2019,
abstract = {Monitoring subtle choroidal thickness changes in the human eye delivers insight into the pathogenesis of various ocular diseases such as myopia and helps planning their treatment. However, a thorough evaluation of detection-performance is challenging as a ground truth for comparison is not available. Alternatively, an artificial ground truth can be generated by averaging the manual expert segmentations. This makes the ground truth very sensitive to ambiguities due to different interpretations by the experts. In order to circumvent this limitation, we present a novel validation approach that operates independently from a ground truth and is uniquely based on the common agreement between algorithm and experts. Utilizing an appropriate index, we compare the joint agreement of several raters with the algorithm and validate it against manual expert segmentation. To illustrate this, we conduct an observational study and evaluate the results obtained using our previously published registration-based method. In addition, we present an adapted state-of-the-art evaluation method, where a paired t-test is carried out after leaving out the results of one expert at the time. Automated and manual detection were performed on a dataset of 90 OCT 3D-volume stack pairs of healthy subjects between 8 and 18 years of age from Asian urban regions with a high prevalence of myopia.},
author = {Ronchetti, Tiziano and Jud, Christoph and Maloca, Peter M. and Org{\"{u}}l, Selim and Giger, Alina T. and Meier, Christoph and Scholl, Hendrik P.N. and Chun, Rachel Ka Man and Liu, Quan and To, Chi Ho and Pova{\v{z}}ay, Boris and Cattin, Philippe C.},
doi = {10.1371/journal.pone.0218776},
file = {:C\:/Users/emeli/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ronchetti et al. - 2019 - Statistical framework for validation without ground truth of choroidal thickness changes detection.pdf:pdf},
issn = {19326203},
journal = {PLoS ONE},
month = {feb},
number = {6},
pmid = {31251762},
publisher = {Public Library of Science},
title = {{Statistical framework for validation without ground truth of choroidal thickness changes detection}},
volume = {14},
year = {2019}
}

@online{WikiChoroid,
  title = {Choroïde},
  year = 2021,
  url = {https://fr.wikipedia.org/wiki/Choro%C3%AFde#Choro%C3%AFde_et_photographie},
}


@article{Fabritius:09,
author = {Tapio Fabritius and Shuichi Makita and Masahiro Miura and Risto Myllyl\"{a} and Yoshiaki Yasuno},
journal = {Opt. Express},
keywords = {Image processing; Pattern recognition; Ophthalmology; Optical coherence tomography; Optical diagnostics for medicine; Image processing; Optic nerve; Optical coherence tomography; Retinal nerve fiber layer; Segmentation; Speckle noise},
number = {18},
pages = {15659--15669},
publisher = {OSA},
title = {Automated segmentation of the macula by optical coherence tomography},
volume = {17},
month = {Aug},
year = {2009},
url = {http://www.opticsexpress.org/abstract.cfm?URI=oe-17-18-15659},
doi = {10.1364/OE.17.015659},
abstract = {This paper presents optical coherence tomography (OCT) signal intensity variation based segmentation algorithms for retinal layer identification. Its main ambition is to reduce the calculation time required by layer identification algorithms. Two algorithms, one for the identification of the internal limiting membrane (ILM) and the other for retinal pigment epithelium (RPE) identification are implemented to evaluate structural features of the retina. Using a 830 nm spectral domain OCT device, this paper demonstrates a segmentation method for the study of healthy and diseased eyes.},
}

@article {Brar597,
	author = {Brar, M and Bartsch, D-U G and Nigam, N and Mojana, F and Gomez, L and Cheng, L and Hedaya, J and Freeman, W R},
	title = {Colour versus grey-scale display of images on high-resolution spectral OCT},
	volume = {93},
	number = {5},
	pages = {597--602},
	year = {2009},
	doi = {10.1136/bjo.2008.146233},
	publisher = {BMJ Publishing Group Ltd},
	abstract = {Aim: To determine whether colour or grey-scale images from high-resolution spectral optical coherence tomography (OCT) are superior in visualising clinically important details of retinal structures.Methods: Patients with macular pathologies were imaged using spectral OCT (OTI, Toronto, Canada). Two reviewers independently analysed the retinal structures and pathologies and graded them on a four-point scale on the basis of the visibility. A third reviewer masked to the results then reviewed images where there was a different score for colour versus grey scale.Results: Statistical analysis showed the grey-scale image to be significantly better in visualising the details of epiretinal membrane, photoreceptor and retinal pigment epithelium layer morphology than the colour scale image (p = 0.00088{\textendash}0.0006). In 16.17\% of eyes, the colour image led to the false impression of photoreceptor disruption.Conclusion: Grey-scale images are qualitatively superior to the colour-scale images on high-resolution spectral OCT. Colour images can be misleading, as the displayed colours are false colours, and the observer may see a dramatic change in colour and interpret that as a large change in the OCT reflectivity.},
	issn = {0007-1161},
	URL = {https://bjo.bmj.com/content/93/5/597},
	eprint = {https://bjo.bmj.com/content/93/5/597.full.pdf},
	journal = {British Journal of Ophthalmology}
}

@article {choroidExpl,
	author = {Pomerleau, Jade},
	title = {Caractérisation des effets de l'hyperglycémie chronique dans la choroïde d'yeux diabétiques},
	year = {2016},
	abstract = {Purpose: Diabetes is an important public health problem, and diabetic retinopathy (DR) is the most common ocular complication. Some studies indicate that the choroid of diabetic patients is affected without apparent signs of DR. Our hypothesis is that the increase of oxidative stress linked to chronic hyperglycemia affects the choroidal function at an early stage of DR. We propose to study glycolysis, mitochondrial metabolism, nitrosative stress and DNA methylation as well as to characterize histological modifications in the diabetic choroid. Methods: The expression of genes/proteins involved in glycolysis, mitochondrial metabolism and production of nitric oxide was compared by DNA microarray and Western blot between healthy and diabetic choroids. Levels of DNA methylation and hydroxymethylation were quantified by slot blot and HPLC-MS/MS in these tissues. Finally, eye sections from healthy or diabetic donors with non-proliferative (NPDR) or proliferative (PDR) DR were colored with Masson’s trichrome and Weigert’s stains. Choroid and Bruch’s membrane thickness, as well as density and diameter of choroidal vessels were analyzed. Results: Our results show a deregulation of the transcriptome of the diabetic choroid, but little variation in the protein expression of validated targets. The global DNA methylation level was similar between diabetic and healthy donors. Our histological analyses demonstrate a thinning of the choroid, and a degeneration of choriocapillaris and choroid veins in diabetic donors with PDR. Conclusions: The study of the choroid is important since damages to this tissue have serious effects on the retinal function. Identification of targets in the choroid opens new perspectives for a preventive treatment of DR.},
	URL = {https://corpus.ulaval.ca/jspui/handle/20.500.11794/27049},
	eprint = {https://corpus.ulaval.ca/jspui/bitstream/20.500.11794/27049/1/32823.pdf},
}

@article {CNNSpatialLocation,
	author = {Osman Semih Kayhan, Jan C. van Gemert},
	title = {Colour versus grey-scale display of images on high-resolution spectral OCT},
	year = {2020},
	publisher = {The Computer Vision Foundation},
	abstract = {In this paper we challenge the common assumption that convolutional layers in modern CNNs are translation invariant. We show that CNNs can and will exploit the absolute spatial location by learning filters that respond exclusively to particular absolute locations by exploiting image boundary effects. Because modern CNNs filters have a huge receptive field, these boundary effects operate even far from the image boundary, allowing the network to exploit absolute spatial location all over the image. We give a simple solution to remove spatial location encoding which improves translation invariance and thus gives a stronger visual inductive bias which particularly benefits small data sets. We broadly demonstrate these benefits on several architectures and various applications such as image classification, patch matching, and two video classification datasets.},
	URL = {},
	eprint = {https://openaccess.thecvf.com/content_CVPR_2020/papers/Kayhan_On_Translation_Invariance_in_CNNs_Convolutional_Layers_Can_Exploit_Absolute_CVPR_2020_paper.pdf}
}


@book{DIDLBook,
author = {Aston Zhang Zachary C Lipton. Mu Li Alexander J. Smola},
title = {Dive into Deep Learning},
url = {https://d2l.ai/},
volume = {10554},
year = {2021}
}

@article{Garrido2014,
   abstract = {Background: Optical coherence tomography (OCT) is an invaluable diagnostic tool for the detection and follow-up of retinal pathology in patients and experimental disease models. However, as morphological structures and layering in health as well as their alterations in disease are complex, segmentation procedures have not yet reached a satisfactory level of performance. Therefore, raw images and qualitative data are commonly used in clinical and scientific reports. Here, we assess the value of OCT reflectivity profiles as a basis for a quantitative characterization of the retinal status in a cross-species comparative study. Methods: Spectral-Domain Optical Coherence Tomography (OCT), confocal Scanning-La-ser Ophthalmoscopy (SLO), and Fluorescein Angiography (FA) were performed in mice (Mus musculus), gerbils (Gerbillus perpadillus), and cynomolgus monkeys (Macaca fascicularis) using the Heidelberg Engineering Spectralis system, and additional SLOs and FAs were obtained with the HRA I (same manufacturer). Reflectivity profiles were extracted from 8-bit greyscale OCT images using the ImageJ software package (http://rsb.info.nih.gov/ij/). Results: Reflectivity profiles obtained from OCT scans of all three animal species correlated well with ex vivo histomorphometric data. Each of the retinal layers showed a typical pattern that varied in relative size and degree of reflectivity across species. In general, plexiform layers showed a higher level of reflectivity than nuclear layers. A comparison of reflectivity profiles from specialized retinal regions (e.g. visual streak in gerbils, fovea in non-human primates) with respective regions of human retina revealed multiple similarities. In a model of Retinitis Pigmentosa (RP), the value of reflectivity profiles for the follow-up of therapeutic interventions was demonstrated. Conclusions: OCT reflectivity profiles provide a detailed, quantitative description of retinal layers and structures including specialized retinal regions. Our results highlight the potential of this approach in the long-term follow-up of therapeutic strategies. © 2014 Garcia Garrido et al.},
   author = {Marina Garcia Garrido and Susanne C. Beck and Regine Mühlfriedel and Sylvie Julien and Ulrich Schraermeyer and Mathias W. Seeliger},
   doi = {10.1371/journal.pone.0100080},
   issn = {19326203},
   issue = {6},
   journal = {PLoS ONE},
   month = {6},
   pmid = {24927180},
   publisher = {Public Library of Science},
   title = {Towards a quantitative OCT image analysis},
   volume = {9},
   year = {2014},
}


@misc{Willdeman2016,
        title = {What is OCT and how can it help ophthalmologists acquire high resolution information on ocular tissue?},
        year = {2016},
        author = {Wildeman et al.},
        howpublished={Available on: \url{https://www.leica-microsystems.com/science-lab/what-is-oct-and-how-can-it-help-ophthalmologists-acquire-high-resolution-information-on-ocular-tissue/}},
        note = {Accessed: 2021-17-05}
     
    }

@Article{Jiang2018,
author={Jiang, Jing
and Liu, Yan
and Chen, Yingchao
and Ma, Bo
and Qian, Yiwen
and Zhang, Zhenzhen
and Zhu, Dongqing
and Wang, Zhiliang
and Xu, Xiaofang},
title={Analysis of Changes in Retinal Thickness in Type 2 Diabetes without Diabetic Retinopathy},
journal={Journal of Diabetes Research},
year={2018},
month={Feb},
day={25},
publisher={Hindawi},
volume={2018},
pages={3082893},
issn={2314-6745},
doi={10.1155/2018/3082893},
url={https://doi.org/10.1155/2018/3082893}
}

@article{DENHAAN2017162,
author = {Den Haan, J
and Frank D. Verbraak 
and Pieter Jelle Visser 
and Femke H. Bouwman},
title = {Retinal thickness in Alzheimer's disease: A systematic review and meta-analysis},
journal = {Alzheimer's \& Dementia: Diagnosis, Assessment \& Disease Monitoring},
volume = {6},
pages = {162 - 170},
year = {2017},
issn = {2352-8729},
howpublished = {available on: \url{http://www.sciencedirect.com/science/article/pii/S2352872916300793}},

}

@incollection{MACNAIR2015343,
title = "Chapter Twenty - Neuroinflammation in Glaucoma and Optic Nerve Damage",
editor = "J. Fielding Hejtmancik and John M. Nickerson",
series = "Progress in Molecular Biology and Translational Science",
publisher = "Academic Press",
volume = "134",
pages = "343 - 363",
year = "2015",
booktitle = "Molecular Biology of Eye Disease",
issn = "1877-1173",
doi = "https://doi.org/10.1016/bs.pmbts.2015.06.010",
url = "http://www.sciencedirect.com/science/article/pii/S187711731500112X",
author = "Caitlin E. {Mac Nair} and Robert W. Nickells",
keywords = "Retinal ganglion cells, Immune privilege, Microglia, Müller cells, Astrocytes, Glaucoma, Neuroinflammation",
abstract = "Glaucoma is a group of optic neuropathies characterized by the degeneration of retinal ganglion cell axons and somas, ultimately preventing light signals in the retina from reaching the brain. Glaucoma is a leading cause of blindness in the world, and treatment options for patients remain limited and minimally efficacious. A number of mechanisms have been linked to glaucomatous pathophysiology. A leading role is now attributed to neuroinflammatory conditions generated by the resident innate immune cells in the optic nerve and retina. Since the eye is immune privileged, the adaptation of these innate immune cells, termed glia, is crucial following trauma. In this chapter, we discuss the mechanisms associated with normal glial function in a healthy eye, and how changes in glial activation can contribute to the process of glaucomatous neurodegeneration in both the optic nerve and retina."
}

@article{BOOIJ20101,
title = "The dynamic nature of Bruch's membrane",
journal = "Progress in Retinal and Eye Research",
volume = "29",
number = "1",
pages = "1 - 18",
year = "2010",
issn = "1350-9462",
doi = "https://doi.org/10.1016/j.preteyeres.2009.08.003",
url = "http://www.sciencedirect.com/science/article/pii/S1350946209000597",
author = "J.C. Booij and D.C. Baas and J. Beisekeeva and T.G.M.F. Gorgels and A.A.B. Bergen",
keywords = "Bruch's membrane, Drusen, AMD, Aging, Molecular composition, Inner collagenous layer, Outer collagenous layer, Elastin layer, Basal membrane",
abstract = "Bruch's membrane (BM) is a unique pentalaminar structure, which is strategically located between the retinal pigment epithelium (RPE) and the fenestrated choroidal capillaries of the eye. BM is an elastin- and collagen-rich extracellular matrix that acts as a molecular sieve. BM partly regulates the reciprocal exchange of biomolecules, nutrients, oxygen, fluids and metabolic waste products between the retina and the general circulation. Accumulating evidence suggests that the molecular, structural and functional properties of BM are dependent on age, genetic constitution, environmental factors, retinal location and disease state. As a result, part of the properties of BM are unique to each human individual at a given age, and therefore uniquely affect the development of normal vision and ocular disease. The changes occurring in BM with age include increased calcification of elastic fibres, increased cross-linkage of collagen fibres and increased turnover of glycosaminoglycans. In addition, advanced glycation end products (AGEs) and fat accumulate in BM. These age-related changes may not only influence the normal age-related health of photoreceptor cells, but also the onset and progression of diseases like retinitis pigmentosa (RP) and age-related macular degeneration (AMD). Undoubtedly, BM is the site of drusen development. Confluent drusen and uncontrolled activation of the complement cascade are most likely the first signs of AMD. Furthermore, the nature of adhesive interactions between the RPE and BM are instrumental in the development of retinal detachments and proliferative retinal disease. Finally, BM is passively or actively involved in a range of other retinal disorders such as Pseudoxanthoma elasticum (PXE), Sorsby's Fundus Dystrophy and Malattia Leventinese. Here, we review the dynamic nature of Bruch's membrane, from molecule to man, during development, aging and disease. We propose a simple and straightforward nomenclature for BM deposits. Finally, we attempt to correlate recently published mRNA expression profiles of the RPE and choroid with molecular, structural and functional properties of BM. Our review may shed light on the complex involvement of BM in retinal pathology, notably age-related macular degeneration."
}

@book{snell1998,
   author = {Snell R. S. and  Lemp M. A.},
   edition = {Second Edition},
   publisher = {Blackwell Science},
   title = {Clinical Anatomy of the Eye},
   year = {1998},
}

@book_section{Rhoades2017,
   author = {William Rhoades and Leila Kump and Eyal Margalit},
   journal = {Neuroimmune Pharmacology},
   pages = {39-54},
   title = {Anterior Chamber and Retina (Structure, Function and Immunology)},
   year = {2017},
}

@misc{eyeanatomy-pic,
        title = {Anatomy of the Eye},
        year = {2021},
        author = {Armenian Eye Care Project},
        howpublished={Available on: \url{https://eyecareproject.com/about-the-eye/how-the-eye-works/anatomy-of-the-eye/}},
        note = {Accessed: 2021-17-05}
     
    }

@book{purves2001,
      title     = {Neuroscience},
      author    = {Purves D and Augustine GJ and Fitzpatrick D and et al},
      year      = {2001},
      publisher = {Sinauer Associates},
      note = {Available from \url{https://www.ncbi.nlm.nih.gov/books/NBK10885/}}
}

@Inbook{Meek2008,
author="Meek, K.M.",
editor="Fratzl, Peter",
title="The Cornea and Sclera",
bookTitle="Collagen: Structure and Mechanics",
year="2008",
publisher="Springer US",
address="Boston, MA",
pages="359--396",
abstract="The cornea and sclera make up the outer tunic of the eye. Each is a connective tissue containing collagen fibrils embedded in a proteoglycan-rich extrafibrillar matrix, but whereas the cornea is uniquely transparent, the sclera is totally opaque. Both tissues require strength to maintain the excess pressure within the eye and to resist external knocks and the forces applied by the extraocular muscles during eye movement. This mechanical strength is provided by the deposition of collagen in a lamellar structure, where the lamellae run parallel to the surface of the tissue rather than through its thickness. The cornea is the main refractive element in the eye's optical system, and it transmits over 90{\%} of the incident light at visible wavelengths. Transparency is achieved because, at the nanoscopic level, the corneal collagen fibrils within the lamellae have a small, uniform diameter and are positioned with respect to each other with a high degree of lateral order. This exquisite arrangement causes destructive interference of scattered light and constructive interference of directly transmitted light throughout the visible wavelengths. As a lens, the cornea also has to be precisely curved, almost spherical near the visual axis but flattening in the periphery. Although the basis of this contour is not fully understood, corneal shape is likely achieved by the arrangement of the collagen at the microscopic level, and it is therefore not surprising that the lamellae have different preferential orientations centrally and peripherally.",
isbn="978-0-387-73906-9",
doi="10.1007/978-0-387-73906-9_13",
url="https://doi.org/10.1007/978-0-387-73906-9_13"
}

@article {SoftMaxClassification,
	author = {Fei Gao and Bing Li and Lei Chen and Zhongyu Shang and Xiang Wei and Chen He},
	title = {A softmax classifier for high-precision classification of ultrasonic similar signals},
	year = {2021},
	doi = {10.1016/j.ultras.2020.106344},
	publisher = {SciencDirect},
	abstract = {High precision classification of ultrasonic signals is helpful to improve the identification and evaluation accuracy for detecting defects. In the previous research, the deep neural network (DNN) has been used to classify the signal with obvious differences. But for different defects of the same depth, or when the defect position is close, the ultrasonic A-scan signal curve is very similar, causing the classification accuracy not high enough. In this paper, an optimized softmax classifier is proposed based on the traditional softmax classifier, and the convolution neural network (CNN) framework is built, which can achieve the accurate classification of signals with similar curves. Through a comparative experiment, the performance of the proposed classifier is evaluated from the loss curve decline rate, classification accuracy and feature visualization. The results show that the classifier has high classification accuracy and strong robustness.},
	URL = {https://www.sciencedirect.com/science/article/pii/S0041624X20302730#b0105},
	eprint = {https://reader.elsevier.com/reader/sd/pii/S0041624X20302730?token=DD1BD2E485417B48310FA6F562FE3DF76BBABFCC883F5CD86EBC592212B80CB47EFE9DA523118039B3AB14476CA45B0B&originRegion=eu-west-1&originCreation=20210518145602}
}


@article {DFTPooling,
	author = {Jongbin Ryu, Ming-Hsuan Yang, Jongwoo Lim},
	title = {DFT-based Transformation Invariant Pooling Layer for Visual Classification},
	year = {2018},
	publisher = {The Computer Vision Foundation},
	abstract = {We propose a novel discrete Fourier transform-based pooling layer for convolutional neural networks. The DFT magnitude pooling replaces the traditional max/average pooling layer between the convolution and fully-connected layers to retain translation invariance and shape preserving (aware of shape difference) properties based on the shift theorem of the Fourier transform. Thanks to the ability to handle image misalignment while keeping important structural information in the pooling stage, the DFT magnitude pooling improves the classification accuracy significantly. In addition, we propose the DFT+ method for ensemble networks using the middle convolution layer outputs. The proposed methods are extensively evaluated on various classification tasks using the ImageNet, CUB 2010-2011, MIT Indoors, Caltech 101, FMD and DTD datasets. The AlexNet, VGG-VD 16, Inception-v3, and ResNet are used as the base networks, upon which DFT and DFT+ methods are implemented. Experimental results show that the proposed methods improve the classification performance in all networks and datasets.},
	URL = {https://openaccess.thecvf.com/content_ECCV_2018/html/Jongbin_Ryu_DFT-based_Transformation_Invariant_ECCV_2018_paper.html},
	eprint = {https://openaccess.thecvf.com/content_ECCV_2018/papers/Jongbin_Ryu_DFT-based_Transformation_Invariant_ECCV_2018_paper.pdf}
}

@article{Ronchetti2019statistic,
   abstract = {Monitoring subtle choroidal thickness changes in the human eye delivers insight into the pathogenesis of various ocular diseases such as myopia and helps planning their treatment. However, a thorough evaluation of detection-performance is challenging as a ground truth for comparison is not available. Alternatively, an artificial ground truth can be generated by averaging the manual expert segmentations. This makes the ground truth very sensitive to ambiguities due to different interpretations by the experts. In order to circumvent this limitation, we present a novel validation approach that operates independently from a ground truth and is uniquely based on the common agreement between algorithm and experts. Utilizing an appropriate index, we compare the joint agreement of several raters with the algorithm and validate it against manual expert segmentation. To illustrate this, we conduct an observational study and evaluate the results obtained using our previously published registration-based method. In addition, we present an adapted state-of-the-art evaluation method, where a paired t-test is carried out after leaving out the results of one expert at the time. Automated and manual detection were performed on a dataset of 90 OCT 3D-volume stack pairs of healthy subjects between 8 and 18 years of age from Asian urban regions with a high prevalence of myopia.},
   author = {Tiziano Ronchetti and Christoph Jud and Peter M. Maloca and Selim Orgül and Alina T. Giger and Christoph Meier and Hendrik P.N. Scholl and Rachel Ka Man Chun and Quan Liu and Chi Ho To and Boris Považay and Philippe C. Cattin},
   doi = {10.1371/journal.pone.0218776},
   issn = {19326203},
   issue = {6},
   journal = {PLoS ONE},
   month = {2},
   pmid = {31251762},
   publisher = {Public Library of Science},
   title = {Statistical framework for validation without ground truth of choroidal thickness changes detection},
   volume = {14},
   year = {2019},
}

@misc{DigitalSreeni,
        title = {Python for Microscopist},
        year = {2016},
        author = {Sreenivas Bhattiprolu},
        howpublished={Available on: \url{https://www.youtube.com/channel/UC34rW-HtPJulxr5wp2Xa04w/featured}},
        note = {Accessed: 2021-05-22}
     
    }
@misc{chollet2015keras,
  title={Keras},
  author={Chollet, Fran\c{c}ois and others},
  year={2015},
  publisher={Keras},
  howpublished={\url{https://keras.io/api/}},
}  

@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@article{Normalization_Vector_Machines:2001,
   abstract = {This article deals with various aspects of normalization in the context of Support Vector Machines. We consider fist normalization of the vectors in the input space and point out the inherent limitations. A natural extension to the feature space is then represented by the kernel function normalization. A correction of the position of the Optimal Separating Hyperplane is subsequently introduced so as to suit better these normalized kernels. Numerical experiments finally evaluate the different approaches.},
   author = {Arnulf B.A. Graf, Silvio Borer},
   doi = {10.1007\%2F3-540-45404-7_37},
   journal = {SpringerLink},
   month = {12},
   title = {Normalization in Support Vector Machines},
   year = {2001},
   URL = {https://link.springer.com/chapter/10.1007/3-540-45404-7_37},

}

@Inbook{Normalizazion_NN,
author="J. Sola; J. Sevilla",
title="Importance of input data normalization for the application of neural networks to complex industrial problems",
month="06",
year="1997",
publisher="IEEE",
pages="1464 - 1468",
abstract="Recent advances in artificial intelligence have allowed the application of such technologies in real industrial problems. We have studied the application of backpropagation neural networks to several problems of estimation and identification in nuclear power plants. These problems often have been reported to be very time-consuming in the training phase. Among the different approaches suggested to ease the backpropagation training process, input data pretreatment has been pointed out, although no specific procedure has been proposed. We have found that input data normalization with certain criteria, prior to a training process, is crucial to obtain good results as well as to fasten significantly the calculations. This paper shows how data normalization affects the performance error of parameter estimators trained to predict the value of several variables of a PWR nuclear power plant. The criteria needed to accomplish such data normalization are also described.",
doi="10.1109/23.589532",
url="https://ieeexplore.ieee.org/document/589532"
}


@Inbook{Normalizazion_NN_classification,
author="T.Jayalakshmi, Dr.A.Santhakumaran",
title="Statistical Normalization and Back Propagation for Classification",
month="02",
year="2011",
publisher="International Journal of Computer Theory and Engineering",
pages="1793-8201",
abstract="The  artificial  neural  network  has  recently  been  applied in many areas of medical and medically related fields. It is known as an excellent classifier of nonlinear input and output numerical data. Some major issues are to be considered before using the neural network models, such as the network structure, learning  rate  parameter,  and  normalization  methods  for  the  input    vectors.    The    proposed    research    showed    various    normalization   methods   used   in   back   propagation   neural   networks to enhance the reliability of the trained network. The experimental   results   showed   that   the   performance   of   the   diabetes  data  classification  model  using  the  neural  networks  was dependent on the normalization methods.",
url="http://www.ijcte.org/papers/288-L052.pdf"
}

@article{AugAndEval:2017,
author="Junhua Ding, XinChuan Li, Venkat N. Gudivada",
title="Augmentation and evaluation of training data for deep learning",
month="12",
year="2017",
publisher="IEEE",
abstract="Recent advances in artificial intelligence have allowed the application of such technologies in real industrial problems. We have studied the application of backpropagation neural networks to several problems of estimation and identification in nuclear power plants. These problems often have been reported to be very time-consuming in the training phase. Among the different approaches suggested to ease the backpropagation training process, input data pretreatment has been pointed out, although no specific procedure has been proposed. We have found that input data normalization with certain criteria, prior to a training process, is crucial to obtain good results as well as to fasten significantly the calculations. This paper shows how data normalization affects the performance error of parameter estimators trained to predict the value of several variables of a PWR nuclear power plant. The criteria needed to accomplish such data normalization are also described.",
doi="10.1109/BigData.2017.8258220",
url="https://ieeexplore.ieee.org/document/8258220",
eprint="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8258220"
}

@article{DatasetSplitting:2011,
author="Kevin K Dobbin, Richard M Simon ",
title="Optimally splitting cases for training and testing high dimensional classifiers",
month="04",
year="2011",
publisher="BMC Medical Genomics",
abstract="Background
We consider the problem of designing a study to develop a predictive classifier from high dimensional data. A common study design is to split the sample into a training set and an independent test set, where the former is used to develop the classifier and the latter to evaluate its performance. In this paper we address the question of what proportion of the samples should be devoted to the training set. How does this proportion impact the mean squared error (MSE) of the prediction accuracy estimate?
Results
We develop a non-parametric algorithm for determining an optimal splitting proportion that can be applied with a specific dataset and classifier algorithm. We also perform a broad simulation study for the purpose of better understanding the factors that determine the best split proportions and to evaluate commonly used splitting strategies (1/2 training or 2/3 training) under a wide variety of conditions. These methods are based on a decomposition of the MSE into three intuitive component parts.
Conclusions
By applying these approaches to a number of synthetic and real microarray datasets we show that for linear classifiers the optimal proportion depends on the overall number of samples available and the degree of differential expression between the classes. The optimal proportion was found to depend on the full dataset size (n) and classification accuracy - with higher accuracy and smaller n resulting in more assigned to the training set. The commonly used strategy of allocating 2/3rd of cases for training was close to optimal for reasonable sized datasets (n ≥ 100) with strong signals (i.e. 85\% or greater full dataset accuracy). In general, we recommend use of our nonparametric resampling approach for determing the optimal split. This approach can be applied to any dataset, using any predictor development method, to determine the best split.",
doi="10.1186/1755-8794-4-31#Abs1",
url="https://bmcmedgenomics.biomedcentral.com/articles/10.1186/1755-8794-4-31#Abs1"
}

@article{Shorten2019,
   abstract = {Deep convolutional neural networks have performed remarkably well on many Computer Vision tasks. However, these networks are heavily reliant on big data to avoid overfitting. Overfitting refers to the phenomenon when a network learns a function with very high variance such as to perfectly model the training data. Unfortunately, many application domains do not have access to big data, such as medical image analysis. This survey focuses on Data Augmentation, a data-space solution to the problem of limited data. Data Augmentation encompasses a suite of techniques that enhance the size and quality of training datasets such that better Deep Learning models can be built using them. The image augmentation algorithms discussed in this survey include geometric transformations, color space augmentations, kernel filters, mixing images, random erasing, feature space augmentation, adversarial training, generative adversarial networks, neural style transfer, and meta-learning. The application of augmentation methods based on GANs are heavily covered in this survey. In addition to augmentation techniques, this paper will briefly discuss other characteristics of Data Augmentation such as test-time augmentation, resolution impact, final dataset size, and curriculum learning. This survey will present existing methods for Data Augmentation, promising developments, and meta-level decisions for implementing Data Augmentation. Readers will understand how Data Augmentation can improve the performance of their models and expand limited datasets to take advantage of the capabilities of big data.},
   author = {Connor Shorten and Taghi M. Khoshgoftaar},
   doi = {10.1186/s40537-019-0197-0},
   issn = {21961115},
   issue = {1},
   journal = {Journal of Big Data},
   keywords = {Big data,Data Augmentation,Deep Learning,GANs,Image data},
   month = {12},
   publisher = {SpringerOpen},
   title = {A survey on Image Data Augmentation for Deep Learning},
   volume = {6},
   year = {2019},
}

@inproceedings{mikolajcyk2018,
   abstract = {These days deep learning is the fastest-growing field in the field of Machine Learning (ML) and Deep Neural Networks (DNN). Among many of DNN structures, the Convolutional Neural Networks (CNN) are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is the lack of sufficient amount of the training data or uneven class balance within the datasets. One of the ways of dealing with this problem is so called data augmentation. In the paper we have compared and analyzed multiple methods of data augmentation in the task of image classification, starting from classical image transformations like rotating, cropping, zooming, histogram based methods and finishing at Style Transfer and Generative Adversarial Networks, along with the representative examples. Next, we presented our own method of data augmentation based on image style transfer. The method allows to generate the new images of high perceptual quality that combine the content of a base image with the appearance of another ones. The newly created images can be used to pre-train the given neural network in order to improve the training process efficiency. Proposed method is validated on the three medical case studies: skin melanomas diagnosis, histopathological images and breast magnetic resonance imaging (MRI) scans analysis, utilizing the image classification in order to provide a diagnose. In such kind of problems the data deficiency is one of the most relevant issues. Finally, we discuss the advantages and disadvantages of the methods being analyzed.},
   author = {Agnieszka Mikołajczyk and Michał Grochowski},
   doi = {10.1109/IIPHDW.2018.8388338},
   isbn = {9781538661437},
   journal = {2018 International Interdisciplinary PhD Workshop, IIPhDW 2018},
   keywords = {Machine learning,data augmentation,deep learning,medical imaging,style transfer},
   month = {6},
   pages = {117-122},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Data augmentation for improving deep learning in image classification problem},
   year = {2018},
}


@article{IoU:2019,
author="Hamid Rezatofighi and Nathan Tsoi and JunYoung Gwak and Amir Sadeghian and Ian Reid and Silvio Savarese",
title="Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression",
year="2019",
publisher="IEEE",
abstract="Intersection over Union (IoU) is the most popular evaluation metric used in the object detection benchmarks. However, there is a gap between optimizing the commonly used distance losses for regressing the parameters of a bounding box and maximizing this metric value. The optimal objective for a metric is the metric itself. In the case of axis-aligned 2D bounding boxes, it can be shown that IoU can be directly used as a regression loss. However, IoU has a plateau making it infeasible to optimize in the case of non-overlapping bounding boxes. In this paper, we address the this weakness by introducing a generalized version of IoU as both a new loss and a new metric. By incorporating this generalized IoU ( GIoU) as a loss into the state-of-the art object detection frameworks, we show a consistent improvement on their performance using both the standard, IoU based, and new, GIoU based, performance measures on popular object detection benchmarks such as PASCAL VOC and MS COCO.",
url="https://openaccess.thecvf.com/content_CVPR_2019/html/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.html",
eprint="https://openaccess.thecvf.com/content_CVPR_2019/papers/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.pdf"
}

@inproceedings{Niwattanakul2013,
author = {Niwattanakul, Suphakit and Singthongchai, Jatsada and Naenudorn, Ekkachai and Wanapu, Supachanun},
year = {2013},
month = {03},
pages = {},
title = {Using of Jaccard Coefficient for Keywords Similarity}
}

@article{ConfusionMatrix,
   abstract = {This paper introduces a new technique for feature selectionand illustrates it on a real data set. Namely, the proposed ap-proach creates subsets of attributes based on two criteria: (1)individual attributes have high discrimination (classification)power;  and (2) the attributes in the subset are complemen-tary - that is, they misclassify different classes.  The methoduses information from a confusion matrix and evaluates oneattribute at a time.},
   author = {Sofia Visa and Brian Ramsay and Anca Ralescu and Esther van der Knaap},
   keywords = {classification, attribute selec-tion, confusion matrix, k-nearest neighbors},
   pages = {120-127},
   publisher = {University of Cincinnati,Ohio},
   title = {Confusion Matrix-based Feature Selection},
   year = {2011},
   eprint="https://www.researchgate.net/profile/Atsushi-Inoue-6/publication/220833227_Page_Ranking_Refinement_Using_Fuzzy_Sets_and_Logic/links/54b743480cf24eb34f6e9e80/Page-Ranking-Refinement-Using-Fuzzy-Sets-and-Logic.pdf#page=126"
}

@Article{Lin2009,
author={Lin, C. C.
and Yoon, M. K.
and Kum, C.
and Erb, M. H.
and McCulley, T. J.},
title={Ethnic Differences in Globe Prominence},
journal={Investigative Ophthalmology {\&} Visual Science},
year={2009},
month={Apr},
day={28},
volume={50},
number={13},
pages={5342-5342},
abstract={An understanding of normal ranges of exophthalmometry has clinical importance for the assessment of globe position. As limited published data exists on exophthalmometry among various ethnic groups, this study compares normal ranges among Asians, African-Americans, Latinos, and Caucasians within a single university service.     A retrospective chart review identified 84 patients evaluated between 9/1/08 and 11/30/08, including 12 Asians, 13 African-Americans, 14 Latinos, and 45 Caucasians. Inclusion criteria were age {\&}gt;17 and adequate documentation of exophthalmometry measurements (Hertel exophthalmometer). Exclusion criteria included any condition affecting globe position, such as a retroorbital mass or thyroid-related orbitopathy. Only right eyes were included.     Mean {\textpm} SD exophthalmometry measurements for various ethnic groups were 14.9 {\textpm} 2.0 (Asian), 17.2 {\textpm} 2.5 (Caucasian), 17.8 {\textpm} 2.9 (Latino), and 20.6 {\textpm} 2.5 (African-American). Based on two-sample t-test calculations, Asians had a statistically significant lower exophthalmometry average than all other ethnic groups (p{\&}lt;0.01) while African-Americans had a statistically significant higher exophthalmometry average than all other ethnic groups (p{\&}lt;0.02). The only comparison that was not statistically significant was between Latinos and Caucasians (p=0.51).     Normal ranges of globe protrusion differ among the four ethnic groups analyzed in this study, with Asians and African-Americans having the lowest and highest values, respectively. These differences may be due to anthropological variations in orbit and skull structure.},
issn={1552-5783}
}

@article{Consejo2020,
   abstract = {Purpose: To evaluate the anterior scleral shape regional differences between Asian and Caucasian populations. Methods: The study included 250 Asian eyes and 235 Caucasian eyes from participants aged 22 to 67 years (38.5 ± 7.6). Three-dimensional (3D) corneo-scleral maps were acquired using a corneo-scleral topographer (Eye Surface Profiler, Eaglet Eye BV) and used to calculate sagittal height. For each 3D map, the sclera (maximum diameter of 18 mm) and cornea were separated at the limbus using an automated technique. Advanced data processing steps were applied to ensure levelled artefact-free datasets to build an average scleral shape map for each population. Results: Statistically, Asian and Caucasian sclerae are significantly different from each other in sagittal height (overall sclera, p = 0.001). The largest difference in sagittal height between groups was found in the inferior-temporal region (271 ± 203 µm, p = 0.03), whereas the smallest difference was found in the superior-temporal region (84 ± 105 µm, p = 0.17). The difference in sagittal height between Caucasian and Asian sclera increases with the distance from the limbus. Conclusions: Asian anterior sclera was found to be less elevated than Caucasian anterior sclera. However, the nasal area of the sclera is less elevated than the temporal area, independently of race. Gaining knowledge in race-related scleral topography differences could assist contact lens manufacturers in the process of lens design and practitioners during the process of contact lens fitting.},
   author = {Alejandra Consejo and Richard Wu and Ahmed Abass},
   doi = {10.3390/jcm9113419},
   issn = {2077-0383},
   issue = {11},
   journal = {Journal of Clinical Medicine},
   month = {10},
   pages = {3419},
   publisher = {MDPI AG},
   title = {Anterior Scleral Regional Variation between Asian and Caucasian Populations},
   volume = {9},
   year = {2020},
}

@Article{IOVINO2017,
author={IOVINO, CLAUDIO
and Napoli, Pietro Emanuele
and Nioi, Matteo
and Sanna, Raffaele
and Paribello, Francesco
and d'Aloja, Ernesto
and Fossarello, Maurizio},
title={Intraobserver variability of post-mortem corneal thickness measurements by using a portable OCT system.},
journal={Investigative Ophthalmology {\&} Visual Science},
year={2017},
month={Jun},
day={23},
volume={58},
number={8},
pages={3516-3516},
abstract={We evaluated the intraobserver variability of post-mortem central corneal thickness (CCT) measurements by using a real-time, portable optical coherence tomography (OCT) system on an animal model.    Participants: Sixteen ocular globes (ovis aries) were analyzed by a portable spectral-domain OCT system (iVue, Optovue Inc, Fremont, CA). All examinations were conducted in the same conditions of temperature (within a range of 12--22{\textdegree}C) and humidity (within a range of 50{\%}--60{\%}) in a dimly lit room. Methods: The OCT scans were performed by two operators at different time-points since death as follows: immediately (i.e. within 10 minutes), at the 30th minute, at the 1st, at the 6th, at the 12th, at the 24th, at the 48th hour, and later (until the 96th hour).Main outcome measures: Repeatability coefficients and intraclass correlation coefficients (ICCs) were calculated for reliability analysis.     Results: The coefficient of repeatability ranged from 0.4{\%} to 3.7{\%} in the central region of the cornea. The ICCs were particularly high during different post-mortem intervals, confirming good reliability of measurements with portable OCT.     Our results suggest that portable OCT is a reliable approach for monitoring CCT variations after death, which may be useful for characterizing the corneas before explantation, detecting quantitative variations during post-mortem corneal degeneration or assessing changes of CCT for forensic implications.  This is an abstract that was submitted for the 2017 ARVO Annual Meeting, held in Baltimore, MD, May 7-11, 2017.},
issn={1552-5783}
}

@article{Mcnabb2009,
   abstract = {Age-related macular degeneration (AMD) is a major cause of vision loss in the elderly. To better study the pathobiology of AMD, postmortem eyes offer an excellent opportunity to correlate optical coherence tomography (OCT) imaging characteristics with histopathology. However, postmortem eyes from autopsy present challenges to standard OCT imaging including opaque anterior segment structures and standard of care autopsy processing resulting in oblique views to the macula. To overcome these challenges, we report a custom periscope attached by a standard mount to an OCT sample arm and demonstrate high quality macular OCT acquisitions in autopsy-processed eyes., "Wide field of view swept-source optical coherence tomography for peripheral retinal disease," Br.},
   author = {Ryan P Mcnabb and James Tian and Sina Farsiu and Joseph A Izatt and Eleonora M Lad and Anthony N Kuo and D B Rein and J S Wittenborn and X Zhang and A A Honeycutt and S B Lesesne and A Folgar and E Yuan and J A Izatt and C A Toth and C A Curcio and J D Messinger and K R Sloan and A Mitra and G McGwin and R F Spaide and Human Chorioretinal and N H Brown and A F Koreishi and M McCall and C B Rickman and H Sattmann and B Hermann and T H Ko and M Stur and A Unterhuber and C Scholda and O Findl and M Wirtitsch and J G Fujimoto and A F Fercher and S J Chiu and X T Li and P Nicholas and S Farsiu and O O Ahsen and Y K Tao and B M Potsaid and Y Sheikine and J Jiang and I Grulkowski and T-h Tsai and V Jayaraman and M F Kraus and J L Connolly and J Hornegger and A Cable and R P McNabb and D S Grewal and R Mehta and S G Schuman and T H Mahmoud and G J Jaffe and P Mruthyunjaya and A N Kuo},
   doi = {10.6084/m9.figshare.4826737},
   issue = {4},
   journal = {Graefes Arch. Clin. Exp. Ophthalmol},
   pages = {1377-1382},
   publisher = {Springer},
   title = {Retinal imaging in human autopsy eyes using a custom optical coherence tomography periscope},
   volume = {127},
   year = {2009},
}
@article{Nioi2019,
   abstract = {Optical coherence tomography (OCT) is an interferometric imaging technique that has revolutionized clinical ophthalmology since the first half of the 1990’s. Despite this approach being successfully employed in ophthalmology and having great potential in forensic cases, its use in different forensic fields appears to be quite limited. In this review we reviewed the scientific literature regarding the application of OCT in forensic science and legal medicine from 1995 to 2019. Our research showed the usefulness of this approach for the study of coronary injuries, postmortem ocular changes, forensic entomology, and several other applications of specific forensic interest (the study of blood stains, fingerprints, and hair bulbs for personal identification, as well as the study of materials found in the crime scene for comparation, or anti-fraud investigation). The creation of specific ‘ad hoc’ devices and a better knowledge of this type of technology by pathologists will be a fundamental step to continue to develop the use of OCT forensic fields.},
   author = {Matteo Nioi and Pietro Emanuele Napoli and Sarah Michelle Mayerson and Maurizio Fossarello and Ernesto d’Aloja},
   doi = {10.1007/s12024-019-00136-z},
   issn = {1547769X},
   issue = {3},
   journal = {Forensic Science, Medicine, and Pathology},
   keywords = {Forensic entomology,Forensic imaging,Forensic pathology,OCT in forensic science,Optical coherence tomography,Postmortem ocular changes},
   month = {9},
   pages = {445-452},
   pmid = {31321632},
   publisher = {Humana Press Inc.},
   title = {Optical coherence tomography in forensic sciences: a review of the literature},
   volume = {15},
   year = {2019},
}

@article{Gabr2016,
   abstract = {Bias is a systemic error in studies that leads to inaccurate deductions. Relevant biases in the field of IR and interventional oncology were identified after reviewing articles published in the Journal of Vascular and Interventional Radiology and CardioVascular and Interventional Radiology. Biases cited in these articles were divided into three categories: preinterventional (health care access, participation, referral, and sample biases), periinterventional (contamination, investigator, and operator biases), and postinterventional (guarantee-time, lead time, loss to follow-up, recall, and reporting biases).},
   author = {Ahmed Gabr and Joseph Ralph Kallini and Kush Desai and Ryan Hickey and Bartley Thornburg and Laura Kulik and Robert J. Lewandowski and Riad Salem},
   doi = {10.1016/j.jvir.2016.01.013},
   issn = {15357732},
   issue = {4},
   journal = {Journal of Vascular and Interventional Radiology},
   month = {4},
   pages = {546-550},
   pmid = {26948329},
   publisher = {Elsevier Inc.},
   title = {Types of research bias encountered in IR},
   volume = {27},
   year = {2016},
}

@Article{Ho2013,
author={Ho, Mary
and Liu, David T.L.
and Chan, Vesta C.K.
and Lam, Dennis S.C.},
title={Choroidal Thickness Measurement in Myopic Eyes by Enhanced Depth Optical Coherence Tomography},
journal={Ophthalmology},
year={2013},
month={Sep},
day={01},
publisher={Elsevier},
volume={120},
number={9},
pages={1909-1914},
issn={0161-6420},
doi={10.1016/j.ophtha.2013.02.005},
url={https://doi.org/10.1016/j.ophtha.2013.02.005}
}


